{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from logs import log\n",
    "import torch\n",
    "# # from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import os\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, GCNConv, GraphSAGE\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import from_networkx, negative_sampling, to_networkx\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN model version logs:\n",
    "    * ver1: GCN first try. (submission.csv)\n",
    "          |_2: Use the testing node embedding for testing & uploading.\n",
    "          |_3: (out_dim=64 --> 32, lr=0.005 --> 0.001)\n",
    "            |_2: Use the testing node embedding for testing & uploading.\n",
    "    * ver2: Add one more fully-connected layer. (fc_submission.csv)\n",
    "          |_2: Use the testing node embedding for testing & uploading.\n",
    "    * ver3: tune hyperparameter (out_dim=64 --> 32, lr=0.005 --> 0.001)\n",
    "          |_2: Use the testing node embedding for testing & uploading.\n",
    "    * ver4: normalize data.x (use ver1 framework, lr=0.005, out_dim=64)\n",
    "          |_2: Use the testing node embedding for testing & uploading.\n",
    "    * ver5: normalize data.x (use ver1 framework, lr=0.005, out_dim=32)\n",
    "          |_2: Use the testing node embedding for testing & uploading.\n",
    "    * ver6:\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Datasets:\n",
    "    * id: edge id, \n",
    "    * from & to: 'from' node point to 'to' node, \n",
    "    * label: connect or not.\n",
    "    * content: containing each node's attribute.\n",
    "\n",
    "   Evaluate:\n",
    "    * AUC: area under ROC curve\n",
    "    * AP: average precision\n",
    "\"\"\"\n",
    "data_path = './dataset1/'\n",
    "model_version = 'GCN_ver6'\n",
    "upload_dataset_info = '_submission'\n",
    "store_file = model_version + upload_dataset_info\n",
    "tra_val_store_file = model_version + '_2' + upload_dataset_info\n",
    "log_file = 'logs/' + store_file + '.log'\n",
    "logger = log(path=data_path, file=log_file)\n",
    "\n",
    "df_train = pd.read_csv(data_path+'raw/train.csv').sort_values('from')\n",
    "df_test = pd.read_csv(data_path+'raw/test.csv')\n",
    "df_content = pd.read_csv(data_path+'raw/content.csv', delimiter='\\t', header=None)\n",
    "df_upload = pd.read_csv(data_path+'raw/upload.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature shape: (877, 1704)\n"
     ]
    }
   ],
   "source": [
    "print(f'Node feature shape: {df_content.shape}')\n",
    "tmp_node_feats = df_content.set_index(0)\n",
    "tmp_node_ids = tmp_node_feats.index.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>E2202</td>\n",
       "      <td>470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>E937</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>E2414</td>\n",
       "      <td>742</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>E3176</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>E960</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>E403</td>\n",
       "      <td>466</td>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>E343</td>\n",
       "      <td>640</td>\n",
       "      <td>874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>E2565</td>\n",
       "      <td>290</td>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>E2136</td>\n",
       "      <td>612</td>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>E1493</td>\n",
       "      <td>378</td>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2572 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   to  from  label\n",
       "266   E2202  470     0      0\n",
       "191    E937  689     0      0\n",
       "891   E2414  742     0      0\n",
       "1066  E3176  677     0      1\n",
       "268    E960  260     0      0\n",
       "...     ...  ...   ...    ...\n",
       "313    E403  466   873      0\n",
       "894    E343  640   874      1\n",
       "2105  E2565  290   875      1\n",
       "1511  E2136  612   875      1\n",
       "469   E1493  378   875      0\n",
       "\n",
       "[2572 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_dataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(Graph_dataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['train.csv', 'content.csv']\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['train.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        self.data = pd.read_csv(self.raw_paths[0]).sort_values('from')\n",
    "        node_feats = pd.read_csv(self.raw_paths[1], delimiter='\\t', header=None, index_col=0)\n",
    "        \n",
    "        # Get node features. [num_nodes, num_node_features]\n",
    "        x = torch.tensor(node_feats.sort_index().values, dtype=torch.float)\n",
    "        \n",
    "        # Get positive data.(label = 1: link)\n",
    "        pos_data = self.data[self.data['label'] == 1]\n",
    "        # neg_data = self.data[self.data['label'] == 0]\n",
    "\n",
    "        # Get edge index.\n",
    "        graph = nx.from_pandas_edgelist(pos_data, 'from', 'to', edge_attr=None)\n",
    "\n",
    "        pair1 = [i[0] for i in graph.edges()]\n",
    "        pair2 = [i[1] for i in graph.edges()]\n",
    "        pos_edge_index = torch.LongTensor([pair1+pair2,pair2+pair1])\n",
    "\n",
    "        # Create Data object.\n",
    "        proc_graph = Data(x=x,\n",
    "                          edge_index=pos_edge_index,\n",
    "                          y=None)\n",
    "        print(proc_graph)\n",
    "\n",
    "        data, slices = self.collate([proc_graph])\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Total content.csv nodes = 2708\n",
    "   Total train.csv nodes = 2704\n",
    "   Total train.csv positive link nodes = 2590\n",
    "\"\"\"\n",
    "demo = Graph_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[877, 1703], edge_index=[2, 2368])\n",
      "877\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]])\n",
      "1703\n"
     ]
    }
   ],
   "source": [
    "for times, data in enumerate(demo, 1):\n",
    "    print(data)\n",
    "    print(data.x.size(0))\n",
    "    print(data.x)\n",
    "    print(data.num_node_features)\n",
    "\n",
    "    # using this to check whether data.edge_index is fulfilled data.x values.\n",
    "    data.validate(raise_on_error=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels) -> None:\n",
    "        super(GCN, self).__init__()\n",
    "        # self.fc1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        # self.conv1 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "    \n",
    "    def encode(self, x, edge_index):\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "    \n",
    "    # def decode_all(self, z):\n",
    "    #     prob_adj = torch.matmul(z, z.t()) # z @ z.t()\n",
    "    #     return(prob_adj > 0).nonzero(as_tuple=False).t()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_link_predictor(model, train_data, val_data, optimizer, criterion, n_epochs=200):\n",
    "    logger.info('Training Start')\n",
    "    for epoch in tqdm(range(1, n_epochs+1)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "        # sampling training negatives for every training epoch\n",
    "        neg_edge_index = negative_sampling(edge_index=train_data.edge_index,\n",
    "                                           num_nodes=train_data.num_nodes,\n",
    "                                           num_neg_samples=train_data.edge_label_index.size(1),\n",
    "                                           method='sparse')\n",
    "        \n",
    "        edge_label_index = torch.cat([train_data.edge_label_index, \n",
    "                                      neg_edge_index], \n",
    "                                      dim=-1)\n",
    "\n",
    "\n",
    "        edge_label = torch.cat([train_data.edge_label,\n",
    "                                train_data.edge_label.new_zeros(neg_edge_index.size(1))], \n",
    "                                dim=0)\n",
    "        \n",
    "        out = model.decode(z, edge_label_index).view(-1)\n",
    "\n",
    "        loss = criterion(out, edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_auc, val_ap = eval_link_predictor(model, train_data, val_data, None)\n",
    "        # print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}')\n",
    "        if epoch % 10 == 0:\n",
    "            # print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}, Val AP: {val_ap:.3f}')\n",
    "            logger.info(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}, Val AP: {val_ap:.3f}')\n",
    "\n",
    "    logger.info('Training End --------------------------------')\n",
    "    return model\n",
    "\n",
    "def eval_link_predictor(model, train_data, val_data, test_data=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if test_data == None: \n",
    "            z = model.encode(train_data.x, train_data.edge_index)\n",
    "        else:\n",
    "            # 'test_data.edge_index' include 'train_data' & 'val_data' pos_edge_index.\n",
    "            z = model.encode(test_data.x, test_data.edge_index)\n",
    "\n",
    "        out = model.decode(z, val_data.edge_label_index).view(-1)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        auc = roc_auc_score(val_data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "        ap = average_precision_score(val_data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "    return auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\mlg_ml\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "INFO Training Start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[877, 1703], edge_index=[2, 2368])\n",
      "Data(x=[877, 1703], edge_index=[2, 2134], edge_label=[1067], edge_label_index=[2, 1067])\n",
      "Data(x=[877, 1703], edge_index=[2, 2134], edge_label=[124], edge_label_index=[2, 124])\n",
      "Data(x=[877, 1703], edge_index=[2, 2258], edge_label=[250], edge_label_index=[2, 250])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22637b81236e48b0988065a7fb8c7ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO Epoch: 010, Train Loss: 0.443, Val AUC: 0.917, Val AP: 0.916\n",
      "INFO Epoch: 020, Train Loss: 0.404, Val AUC: 0.925, Val AP: 0.921\n",
      "INFO Epoch: 030, Train Loss: 0.410, Val AUC: 0.924, Val AP: 0.925\n",
      "INFO Epoch: 040, Train Loss: 0.403, Val AUC: 0.907, Val AP: 0.913\n",
      "INFO Epoch: 050, Train Loss: 0.391, Val AUC: 0.889, Val AP: 0.900\n",
      "INFO Epoch: 060, Train Loss: 0.399, Val AUC: 0.894, Val AP: 0.906\n",
      "INFO Epoch: 070, Train Loss: 0.389, Val AUC: 0.902, Val AP: 0.911\n",
      "INFO Epoch: 080, Train Loss: 0.389, Val AUC: 0.909, Val AP: 0.919\n",
      "INFO Epoch: 090, Train Loss: 0.393, Val AUC: 0.895, Val AP: 0.907\n",
      "INFO Epoch: 100, Train Loss: 0.379, Val AUC: 0.877, Val AP: 0.901\n",
      "INFO Epoch: 110, Train Loss: 0.387, Val AUC: 0.877, Val AP: 0.899\n",
      "INFO Epoch: 120, Train Loss: 0.378, Val AUC: 0.876, Val AP: 0.900\n",
      "INFO Epoch: 130, Train Loss: 0.384, Val AUC: 0.880, Val AP: 0.903\n",
      "INFO Epoch: 140, Train Loss: 0.386, Val AUC: 0.882, Val AP: 0.900\n",
      "INFO Epoch: 150, Train Loss: 0.377, Val AUC: 0.880, Val AP: 0.895\n",
      "INFO Epoch: 160, Train Loss: 0.385, Val AUC: 0.879, Val AP: 0.899\n",
      "INFO Epoch: 170, Train Loss: 0.378, Val AUC: 0.891, Val AP: 0.909\n",
      "INFO Epoch: 180, Train Loss: 0.375, Val AUC: 0.887, Val AP: 0.905\n",
      "INFO Epoch: 190, Train Loss: 0.382, Val AUC: 0.884, Val AP: 0.905\n",
      "INFO Epoch: 200, Train Loss: 0.387, Val AUC: 0.885, Val AP: 0.905\n",
      "INFO Epoch: 210, Train Loss: 0.384, Val AUC: 0.890, Val AP: 0.908\n",
      "INFO Epoch: 220, Train Loss: 0.381, Val AUC: 0.891, Val AP: 0.908\n",
      "INFO Epoch: 230, Train Loss: 0.380, Val AUC: 0.885, Val AP: 0.909\n",
      "INFO Epoch: 240, Train Loss: 0.384, Val AUC: 0.882, Val AP: 0.908\n",
      "INFO Epoch: 250, Train Loss: 0.394, Val AUC: 0.879, Val AP: 0.907\n",
      "INFO Epoch: 260, Train Loss: 0.376, Val AUC: 0.873, Val AP: 0.900\n",
      "INFO Epoch: 270, Train Loss: 0.375, Val AUC: 0.877, Val AP: 0.902\n",
      "INFO Epoch: 280, Train Loss: 0.374, Val AUC: 0.855, Val AP: 0.887\n",
      "INFO Epoch: 290, Train Loss: 0.378, Val AUC: 0.871, Val AP: 0.897\n",
      "INFO Epoch: 300, Train Loss: 0.374, Val AUC: 0.875, Val AP: 0.901\n",
      "INFO Training End --------------------------------\n",
      "INFO Test AUC: 0.866, Test AP: 0.889\n",
      "INFO tra_val Test AUC: 0.871, Test AP: 0.894\n"
     ]
    }
   ],
   "source": [
    "data = demo.data\n",
    "# data = T.NormalizeFeatures()(data)\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(num_val=0.05, \n",
    "                                                    num_test=0.1, \n",
    "                                                    is_undirected=True, \n",
    "                                                    add_negative_train_samples=False\n",
    "                                                    )(data)\n",
    "print(data)\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(data.num_features, 128, 32).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = train_link_predictor(model, train_data, val_data, optimizer, criterion, n_epochs=300)\n",
    "\n",
    "test_auc, test_ap = eval_link_predictor(model, train_data, test_data, None)\n",
    "logger.info(f\"Test AUC: {test_auc:.3f}, Test AP: {test_ap:.3f}\")\n",
    "test_auc, test_ap = eval_link_predictor(model, train_data, test_data, test_data)\n",
    "logger.info(f\"tra_val Test AUC: {test_auc:.3f}, Test AP: {test_ap:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(data_path+'raw/test.csv')\n",
    "test_feats = pd.read_csv(data_path+'raw/content.csv', delimiter='\\t', header=None, index_col=0)\n",
    "test_x = torch.tensor(test_feats.sort_index().values, dtype=torch.float)\n",
    "test_id = test_df['id'].values\n",
    "test_edge_index = torch.tensor(test_df[['from', 'to']].values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6190, 0.9709, 0.9561, 0.7320, 0.3349, 0.7913, 0.6741, 0.8253, 0.9254,\n",
      "        0.4418, 0.4138, 0.7324, 0.7034, 0.7959, 0.3676, 0.9055, 0.4899, 0.5604,\n",
      "        0.5313, 0.5169, 0.9977, 0.3090, 0.9334, 0.4100, 0.4352, 0.4613, 0.9584,\n",
      "        0.4698, 0.6404, 0.7925, 0.3101, 0.9486, 0.9747, 0.9862, 0.8151, 0.7315,\n",
      "        0.6564, 0.9800, 0.9876, 0.4678, 0.9417, 0.5968, 0.4183, 0.4993, 0.3933,\n",
      "        0.6218, 0.8290, 0.4588, 0.9973, 0.4077, 0.3325, 0.4372, 0.4382, 0.6675,\n",
      "        0.8001, 0.3850, 0.9756, 0.5160, 0.3732, 0.7520, 0.9552, 0.5900, 0.2158,\n",
      "        0.3715, 0.6578, 0.9296, 0.5598, 0.6836, 0.3514, 0.3723, 0.3925, 0.6533,\n",
      "        0.8393, 0.4605, 0.9320, 0.4045, 0.8981, 0.9748, 0.2287, 0.8354, 0.8890,\n",
      "        0.4663, 0.7931, 0.8108, 0.9935, 0.4055, 0.9934, 0.5956, 0.9285, 0.9842,\n",
      "        0.9278, 0.7946, 0.8219, 0.4433, 0.4454, 0.3936, 0.9558, 0.4014, 0.3865,\n",
      "        0.4205, 0.9784, 0.2887, 0.8600, 0.6646, 0.6539, 0.7229, 0.7422, 0.9721,\n",
      "        0.9742, 0.9939, 0.4093, 0.4704, 0.3538, 0.9961, 0.5972, 0.6680, 0.9928,\n",
      "        0.4388, 0.9484, 0.4758, 0.6060, 0.7101, 0.4528, 0.2266, 0.4311, 0.3738,\n",
      "        0.6199, 0.8592, 0.4605, 0.4670, 0.9942, 0.4948, 0.6407, 0.5761, 0.9754,\n",
      "        0.9084, 0.4900, 0.4044, 0.4708, 0.5697, 0.5874, 0.3723, 0.9054, 0.7369,\n",
      "        0.5137, 0.5551, 0.2651, 0.8621, 0.7456, 0.4113, 0.7679, 0.9297, 0.4869,\n",
      "        0.5371, 0.6604, 0.7402, 0.4383, 0.9345, 0.4691, 0.7229, 0.9099, 0.7765,\n",
      "        0.4031, 0.4446, 0.4840, 0.6105, 0.4386, 0.4426, 0.8072, 0.6317, 0.9935,\n",
      "        0.5797, 0.8388, 0.4684, 0.4965, 0.5240, 0.3927, 0.7431, 0.7405, 0.9109,\n",
      "        0.4826, 0.6350, 0.6895, 0.4903, 0.4275, 0.8468, 0.9944, 0.9974, 0.9743,\n",
      "        0.7640, 0.4516, 0.9748, 0.7292, 0.5988, 0.5068, 0.4205, 0.6268, 0.4021,\n",
      "        0.9988, 0.4057, 0.9806, 0.6205, 0.4057, 0.4195, 0.9989, 0.9884, 0.4113,\n",
      "        0.9973, 0.6057, 0.4056, 0.9732, 0.4694, 0.9042, 0.4858, 0.4329, 0.9700,\n",
      "        0.6231, 0.9416, 0.6312, 0.3930, 0.5149, 0.4123, 0.6120, 0.6377, 0.5580,\n",
      "        0.5863, 0.5154, 0.9434, 0.7124, 0.4703, 0.9526, 0.4331, 0.9919, 0.5722,\n",
      "        0.9931, 0.9033, 0.2503, 0.6391, 0.9571, 0.4883, 0.9750, 0.6567, 0.2162,\n",
      "        0.3276, 0.4974, 0.6844, 0.9248, 0.4197, 0.9897, 0.4734, 0.8492, 0.4081,\n",
      "        0.3708, 0.8903, 0.6367, 0.9407, 0.4112, 0.9130, 0.6800, 0.3406, 0.9962,\n",
      "        0.8761, 0.3916, 0.5512, 0.9521, 0.3732, 0.4823, 0.0880, 0.8774, 0.3925,\n",
      "        0.9760, 0.4985, 0.3275, 0.4628, 0.4943, 0.4726, 0.3934, 0.3480, 0.5133,\n",
      "        0.3578, 0.3809, 0.4673, 0.9507, 0.9956, 0.9808, 0.5438, 0.8518, 0.4674,\n",
      "        0.3239, 0.9641, 0.9150, 0.9387, 0.6155, 0.3942, 0.5345, 0.4559, 0.4592,\n",
      "        0.6074, 0.9971, 0.9744, 0.4623, 0.9766, 0.6997, 0.6855, 0.7138, 0.2529,\n",
      "        0.9930, 0.7767, 0.5172, 0.5464, 0.4482, 0.9574, 0.8393, 0.4255, 0.5106,\n",
      "        0.9119, 0.9572, 0.3272, 0.9291, 0.3664, 0.9654, 0.4981, 0.9401, 0.4286,\n",
      "        0.3972, 0.5426, 0.6468, 0.7080, 0.2267, 0.2168, 0.9812, 0.9526, 0.4726,\n",
      "        0.8531, 0.6155, 0.4974, 0.3636, 0.1392, 0.9253, 0.2520, 0.4526, 0.6642,\n",
      "        0.3462, 0.4123, 0.9706, 0.7961, 0.8083, 0.7216, 0.9937, 0.9916, 0.5123,\n",
      "        0.4257, 0.9878, 0.9310, 0.7892, 0.6861, 0.5356, 0.5249, 0.9687, 0.5442,\n",
      "        0.6989, 0.5480, 0.8329, 0.3403, 0.4950, 0.5492, 0.9777, 0.2271, 0.7776,\n",
      "        0.9968, 0.4157, 0.6505, 0.4951, 0.9821, 0.9459, 0.7686, 0.9819, 0.9596,\n",
      "        0.6141, 0.3612, 0.4296, 0.4332, 0.8987, 0.4319, 0.7822, 0.3640, 0.5111,\n",
      "        0.5006, 0.5585, 0.5830, 0.5629, 0.9333, 0.4079, 0.5126, 0.3344, 0.4221,\n",
      "        0.5774, 0.5215, 0.5234, 0.9491, 0.3618, 0.4287, 0.5961, 0.4635, 0.4727,\n",
      "        0.8708, 0.3741, 0.9902, 0.9272, 0.0559, 0.8798, 0.9368, 0.9882, 0.9918,\n",
      "        0.4649, 0.9968, 0.9814, 0.9570, 0.8392, 0.5073, 0.8701, 0.8989, 0.6400,\n",
      "        0.9882, 0.9811, 0.4715, 0.3941, 0.5607, 0.4759, 0.9496, 0.9100, 0.6272,\n",
      "        0.4257, 0.3557, 0.8884, 0.6282, 0.4894, 0.5785, 0.5660, 0.9685, 0.5065,\n",
      "        0.9117, 0.5542, 0.2404, 0.4921, 0.9269, 0.5226, 0.6717, 0.3836, 0.8024,\n",
      "        0.7372, 0.8465, 0.8355, 0.9106, 0.9991, 0.3277, 0.9998, 0.3722, 0.4611,\n",
      "        0.9239, 0.9446, 0.9650, 0.5497, 0.4684, 0.4868, 0.9797, 0.6016, 0.6066,\n",
      "        0.9823, 0.9958, 0.5598, 0.7998, 0.8430, 0.7247, 0.8254, 0.2527, 0.9292,\n",
      "        0.9241, 0.9337, 0.9790, 0.9654, 0.9899, 0.9741, 0.7514, 0.8363, 0.7327,\n",
      "        0.7758, 0.5560, 0.7890, 0.9847, 0.4504, 0.5521, 0.5630, 0.8979, 0.4315,\n",
      "        0.9197, 0.5856, 0.7986, 0.3661, 0.9360, 0.3746, 0.8798, 0.3368, 0.5183,\n",
      "        0.5391, 0.9707, 0.2882, 0.6896, 0.4959, 0.9792, 0.9127, 0.5782, 0.3531,\n",
      "        0.5253, 0.5498, 0.5231, 0.4330, 0.6639, 0.4429, 0.6901, 0.8217, 0.9935,\n",
      "        0.4517, 0.7202, 0.6480, 0.6114, 0.4700, 0.6020, 0.9900, 0.9524, 0.4583,\n",
      "        0.6357, 0.4564, 0.6053, 0.4735, 0.9884, 0.4398, 0.9362, 0.9484, 0.8139,\n",
      "        0.9591, 0.9949, 0.9903, 0.5748, 0.8413, 0.9996, 0.5272, 0.9319, 0.4995,\n",
      "        0.6001, 0.5962, 0.4934, 0.5550, 0.8717, 0.4547, 0.9537, 0.5033, 0.7663,\n",
      "        0.9963, 0.7658, 0.5089, 0.7462, 0.2233, 0.4235, 0.4169, 0.9919, 0.8768,\n",
      "        0.4526, 0.6201, 0.6273, 0.7952, 0.8863, 0.3638, 0.9979, 0.4480, 0.4435,\n",
      "        0.4751, 0.5350, 0.3828, 0.6550, 0.3886, 0.5258, 0.9771, 0.9317, 0.4533,\n",
      "        0.5745, 0.1530, 0.4796, 0.6225, 0.5654, 0.8846, 0.4708, 0.5215, 0.5096,\n",
      "        0.8449, 0.9468, 0.6287, 0.5851, 0.3161, 0.6136, 0.9260, 0.7432, 0.3441,\n",
      "        0.6246, 0.4277, 0.5827, 0.9391, 0.3948, 0.4269, 0.8093, 0.3585, 0.6808,\n",
      "        0.6743, 0.4518, 0.5882, 0.9751, 0.5772, 0.2926, 0.6480, 0.4619, 0.4852,\n",
      "        0.9409, 0.6198, 0.7001, 0.4088, 0.4537, 0.3434, 0.7370, 0.8999, 0.5607,\n",
      "        0.4694, 0.9159, 0.4761, 0.8697, 0.5854, 0.4833, 0.9180, 0.3163, 0.9878,\n",
      "        0.4758, 0.9906, 0.6049, 0.4861, 0.9661])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    out = model.decode(z, test_edge_index).view(-1)\n",
    "    out = torch.sigmoid(out)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['id', 'prob']\n",
    "out = out.numpy()\n",
    "output_csv = []\n",
    "for ind, val in enumerate(test_id):\n",
    "    output_csv.append([val, str(out[ind])])\n",
    "output_csv = pd.DataFrame(output_csv, columns=header)\n",
    "output_csv.to_csv(data_path+'submission/'+store_file+'.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tra_val inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(data_path+'raw/test.csv')\n",
    "test_feats = pd.read_csv(data_path+'raw/content.csv', delimiter='\\t', header=None, index_col=0)\n",
    "test_x = torch.tensor(test_feats.sort_index().values, dtype=torch.float)\n",
    "test_id = test_df['id'].values\n",
    "test_edge_index = torch.tensor(test_df[['from', 'to']].values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5677, 0.9660, 0.9558, 0.7285, 0.3548, 0.7811, 0.6699, 0.8333, 0.9242,\n",
      "        0.4389, 0.4180, 0.7299, 0.6954, 0.8245, 0.3685, 0.9055, 0.4942, 0.6369,\n",
      "        0.5320, 0.5173, 0.9968, 0.3128, 0.9206, 0.4121, 0.4339, 0.4615, 0.9584,\n",
      "        0.4931, 0.6428, 0.7852, 0.2705, 0.9461, 0.9746, 0.9855, 0.8027, 0.7196,\n",
      "        0.6123, 0.9796, 0.9813, 0.4686, 0.9416, 0.5255, 0.4363, 0.4991, 0.3836,\n",
      "        0.6051, 0.8133, 0.4536, 0.9965, 0.4264, 0.3325, 0.4359, 0.4383, 0.6675,\n",
      "        0.9469, 0.3850, 0.9745, 0.5076, 0.3994, 0.7441, 0.9413, 0.5884, 0.2158,\n",
      "        0.3721, 0.6603, 0.9187, 0.5565, 0.7165, 0.5099, 0.3726, 0.4020, 0.7131,\n",
      "        0.8393, 0.4160, 0.9320, 0.4105, 0.9000, 0.9683, 0.2559, 0.8421, 0.8780,\n",
      "        0.4596, 0.7649, 0.8231, 0.9919, 0.4130, 0.9901, 0.5931, 0.9250, 0.9842,\n",
      "        0.9297, 0.7936, 0.8069, 0.4485, 0.4790, 0.3941, 0.9565, 0.4023, 0.3934,\n",
      "        0.4410, 0.9735, 0.3321, 0.8558, 0.6594, 0.6532, 0.7088, 0.7333, 0.9730,\n",
      "        0.9730, 0.9935, 0.4120, 0.4699, 0.3656, 0.9857, 0.5856, 0.6680, 0.9912,\n",
      "        0.4433, 0.9419, 0.4784, 0.6039, 0.7001, 0.4470, 0.2421, 0.4329, 0.3605,\n",
      "        0.6198, 0.9841, 0.4590, 0.4672, 0.9942, 0.4601, 0.6416, 0.5647, 0.9753,\n",
      "        0.9362, 0.4897, 0.3695, 0.4707, 0.5902, 0.5809, 0.4256, 0.9027, 0.7120,\n",
      "        0.5137, 0.5608, 0.2802, 0.8359, 0.7278, 0.4400, 0.7865, 0.9128, 0.5008,\n",
      "        0.4605, 0.6624, 0.7241, 0.4393, 0.9503, 0.4700, 0.7181, 0.8967, 0.7765,\n",
      "        0.4065, 0.4450, 0.5097, 0.6092, 0.3819, 0.4539, 0.7339, 0.6105, 0.9913,\n",
      "        0.4547, 0.8421, 0.4628, 0.4687, 0.5178, 0.3901, 0.7430, 0.7344, 0.9134,\n",
      "        0.4258, 0.6361, 0.6896, 0.4903, 0.4263, 0.8400, 0.9921, 0.9959, 0.9743,\n",
      "        0.7461, 0.4520, 0.9718, 0.7242, 0.6008, 0.5068, 0.4194, 0.6268, 0.4072,\n",
      "        0.9985, 0.4118, 0.9785, 0.6167, 0.4591, 0.4284, 0.9989, 0.9835, 0.4257,\n",
      "        0.9960, 0.6047, 0.3882, 0.9725, 0.4710, 0.9042, 0.4873, 0.4332, 0.9688,\n",
      "        0.6154, 0.9113, 0.6309, 0.3830, 0.5150, 0.4022, 0.6116, 0.6370, 0.7633,\n",
      "        0.5724, 0.5386, 0.9434, 0.7124, 0.4695, 0.9562, 0.4332, 0.9915, 0.5730,\n",
      "        0.9931, 0.9034, 0.2572, 0.6406, 0.9419, 0.4883, 0.9707, 0.6507, 0.2160,\n",
      "        0.3310, 0.5191, 0.6786, 0.9014, 0.4233, 0.9876, 0.4717, 0.8434, 0.4375,\n",
      "        0.3792, 0.8805, 0.5481, 0.9047, 0.4111, 0.9087, 0.6744, 0.3409, 0.9849,\n",
      "        0.8758, 0.3916, 0.5512, 0.9521, 0.3454, 0.4963, 0.1042, 0.8774, 0.4184,\n",
      "        0.9766, 0.4917, 0.3629, 0.4628, 0.4924, 0.4726, 0.3997, 0.3458, 0.5262,\n",
      "        0.3770, 0.3851, 0.4652, 0.9455, 0.9947, 0.9722, 0.5321, 0.8501, 0.4687,\n",
      "        0.3262, 0.9611, 0.9135, 0.9252, 0.6156, 0.3942, 0.5345, 0.4570, 0.4581,\n",
      "        0.6065, 0.9970, 0.9720, 0.4623, 0.9500, 0.6602, 0.6806, 0.6676, 0.2538,\n",
      "        0.9914, 0.7691, 0.5584, 0.5318, 0.4261, 0.9525, 0.8299, 0.4246, 0.5096,\n",
      "        0.9030, 0.9564, 0.3401, 0.8557, 0.3662, 0.9646, 0.4962, 0.9396, 0.4168,\n",
      "        0.3981, 0.5404, 0.6441, 0.6915, 0.5454, 0.2236, 0.9779, 0.9517, 0.4777,\n",
      "        0.8467, 0.6058, 0.4974, 0.3587, 0.1457, 0.9193, 0.2936, 0.4526, 0.6267,\n",
      "        0.3481, 0.4016, 0.9693, 0.7961, 0.7946, 0.7118, 0.9934, 0.9834, 0.5110,\n",
      "        0.4280, 0.9878, 0.9073, 0.7840, 0.6810, 0.5280, 0.5225, 0.9631, 0.5441,\n",
      "        0.7005, 0.5480, 0.8132, 0.3416, 0.4964, 0.6099, 0.9757, 0.2320, 0.7713,\n",
      "        0.9968, 0.4069, 0.6528, 0.4923, 0.9823, 0.9696, 0.7686, 0.9812, 0.8433,\n",
      "        0.6140, 0.3601, 0.4286, 0.4363, 0.9014, 0.4272, 0.7822, 0.3600, 0.5046,\n",
      "        0.4994, 0.5486, 0.5830, 0.5629, 0.8831, 0.4218, 0.5130, 0.3374, 0.4258,\n",
      "        0.5743, 0.5127, 0.5118, 0.9622, 0.3595, 0.4287, 0.5959, 0.4639, 0.4676,\n",
      "        0.8721, 0.3825, 0.9900, 0.9408, 0.0677, 0.8777, 0.9368, 0.9856, 0.9918,\n",
      "        0.4554, 0.9955, 0.9779, 0.9333, 0.8226, 0.4924, 0.8650, 0.8812, 0.7694,\n",
      "        0.9847, 0.9914, 0.4715, 0.3916, 0.5584, 0.4636, 0.9443, 0.9046, 0.6286,\n",
      "        0.4264, 0.3689, 0.8872, 0.6269, 0.4899, 0.4974, 0.6823, 0.9480, 0.5129,\n",
      "        0.8845, 0.5509, 0.2405, 0.4871, 0.9260, 0.5201, 0.6662, 0.3848, 0.8119,\n",
      "        0.7281, 0.8305, 0.8355, 0.9485, 0.9986, 0.3311, 0.9998, 0.3713, 0.4604,\n",
      "        0.9148, 0.9416, 0.9711, 0.5594, 0.4667, 0.4861, 0.9797, 0.6017, 0.6066,\n",
      "        0.9802, 0.9957, 0.6237, 0.7897, 0.8110, 0.7165, 0.8243, 0.2585, 0.9540,\n",
      "        0.9306, 0.9309, 0.9785, 0.9652, 0.9882, 0.9697, 0.7437, 0.8242, 0.7299,\n",
      "        0.7725, 0.5557, 0.7889, 0.9786, 0.4511, 0.5498, 0.5595, 0.8953, 0.4374,\n",
      "        0.9197, 0.7459, 0.7773, 0.3690, 0.9344, 0.3744, 0.8842, 0.3334, 0.5183,\n",
      "        0.5305, 0.9707, 0.2922, 0.6878, 0.4959, 0.9791, 0.9074, 0.5778, 0.3701,\n",
      "        0.5217, 0.5478, 0.5231, 0.4490, 0.7053, 0.4413, 0.6388, 0.7814, 0.9930,\n",
      "        0.4680, 0.7188, 0.6395, 0.5987, 0.4700, 0.5984, 0.9896, 0.9435, 0.4597,\n",
      "        0.6364, 0.4673, 0.5836, 0.4735, 0.9878, 0.4455, 0.9184, 0.9419, 0.8105,\n",
      "        0.9336, 0.9949, 0.9850, 0.5737, 0.8317, 0.9990, 0.5270, 0.9482, 0.4982,\n",
      "        0.6171, 0.5975, 0.4877, 0.5549, 0.8715, 0.4582, 0.9544, 0.4967, 0.7594,\n",
      "        0.9961, 0.7550, 0.5016, 0.7381, 0.2399, 0.4253, 0.4006, 0.9918, 0.8757,\n",
      "        0.4378, 0.6188, 0.6273, 0.8911, 0.8754, 0.3845, 0.9972, 0.4465, 0.4434,\n",
      "        0.4751, 0.5338, 0.3829, 0.6601, 0.4071, 0.5406, 0.9749, 0.9312, 0.4543,\n",
      "        0.5639, 0.1567, 0.4816, 0.6469, 0.5640, 0.8800, 0.4710, 0.5215, 0.5087,\n",
      "        0.8441, 0.9468, 0.6202, 0.5834, 0.3317, 0.6127, 0.9666, 0.7425, 0.3483,\n",
      "        0.6265, 0.4303, 0.5617, 0.9348, 0.3988, 0.4433, 0.7323, 0.3833, 0.6585,\n",
      "        0.6742, 0.8218, 0.5519, 0.9708, 0.5769, 0.2927, 0.6395, 0.4612, 0.4887,\n",
      "        0.9358, 0.6127, 0.6944, 0.7902, 0.4556, 0.3461, 0.7307, 0.8940, 0.5607,\n",
      "        0.5137, 0.9126, 0.6033, 0.8528, 0.5793, 0.4555, 0.9136, 0.3163, 0.9890,\n",
      "        0.4055, 0.9887, 0.5920, 0.4861, 0.9637])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(test_data.x, test_data.edge_index)\n",
    "\n",
    "    out = model.decode(z, test_edge_index).view(-1)\n",
    "    out = torch.sigmoid(out)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['id', 'prob']\n",
    "out = out.numpy()\n",
    "output_csv = []\n",
    "for ind, val in enumerate(test_id):\n",
    "    output_csv.append([val, str(out[ind])])\n",
    "output_csv = pd.DataFrame(output_csv, columns=header)\n",
    "output_csv.to_csv(data_path+'submission/'+tra_val_store_file+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64049391f96ba131a9e04c522b3e94cd43efdce572641ac76d85c52ad35b8cda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
