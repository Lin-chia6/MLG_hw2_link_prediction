{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from logs import log\n",
    "from tqdm.notebook import tqdm\n",
    "# from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, GCNConv, GAE, VGAE, APPNP\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import from_networkx, negative_sampling, to_networkx\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNAE model version logs:\n",
    "    * ver1: copy VGNAE.ipynb then change Encoder & model. \n",
    "          |_2: Use the testing node embedding for testing & uploading.\n",
    "    * ver2: tune hyperparameter(APPNP alpha=0.15)\n",
    "          |_2: Use the testing node embedding for testing & uploading."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Datasets:\n",
    "    * id: edge id, \n",
    "    * from & to: 'from' node point to 'to' node, \n",
    "    * label: connect or not.\n",
    "    * content: containing each node's attribute.\n",
    "\n",
    "   Evaluate:\n",
    "    * AUC: area under ROC curve\n",
    "    * AP: average precision\n",
    "\"\"\"\n",
    "data_path = './dataset1/'\n",
    "store_file = 'unGNAE_ver3_submission'\n",
    "log_file = 'logs/'+store_file+'.log'\n",
    "logger = log(path=data_path, file=log_file)\n",
    "\n",
    "df_train = pd.read_csv(data_path+'raw/train.csv')\n",
    "df_test = pd.read_csv(data_path+'raw/test.csv')\n",
    "df_content = pd.read_csv(data_path+'raw/content.csv', delimiter='\\t', header=None)\n",
    "df_upload = pd.read_csv(data_path+'raw/upload.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature shape: (2708, 1434)\n"
     ]
    }
   ],
   "source": [
    "print(f'Node feature shape: {df_content.shape}')\n",
    "tmp_node_feats = df_content.set_index(0)\n",
    "tmp_node_ids = tmp_node_feats.index.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E10311</td>\n",
       "      <td>2399</td>\n",
       "      <td>2339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E10255</td>\n",
       "      <td>2397</td>\n",
       "      <td>1144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E10667</td>\n",
       "      <td>854</td>\n",
       "      <td>1726</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E9395</td>\n",
       "      <td>872</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E5926</td>\n",
       "      <td>2450</td>\n",
       "      <td>1312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681</th>\n",
       "      <td>E1171</td>\n",
       "      <td>1643</td>\n",
       "      <td>1383</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8682</th>\n",
       "      <td>E4741</td>\n",
       "      <td>1879</td>\n",
       "      <td>1443</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8683</th>\n",
       "      <td>E9256</td>\n",
       "      <td>171</td>\n",
       "      <td>1711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8684</th>\n",
       "      <td>E4322</td>\n",
       "      <td>633</td>\n",
       "      <td>2440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8685</th>\n",
       "      <td>E4434</td>\n",
       "      <td>122</td>\n",
       "      <td>1222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8686 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    to  from  label\n",
       "0     E10311  2399  2339      0\n",
       "1     E10255  2397  1144      1\n",
       "2     E10667   854  1726      0\n",
       "3      E9395   872   702      0\n",
       "4      E5926  2450  1312      1\n",
       "...      ...   ...   ...    ...\n",
       "8681   E1171  1643  1383      0\n",
       "8682   E4741  1879  1443      1\n",
       "8683   E9256   171  1711      1\n",
       "8684   E4322   633  2440      1\n",
       "8685   E4434   122  1222      1\n",
       "\n",
       "[8686 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_dataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(Graph_dataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['train.csv', 'content.csv']\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['train.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        self.data = pd.read_csv(self.raw_paths[0]).sort_values('from')\n",
    "        node_feats = pd.read_csv(self.raw_paths[1], delimiter='\\t', header=None, index_col=0)\n",
    "        \n",
    "        # Get node features. [num_nodes, num_node_features]\n",
    "        x = torch.tensor(node_feats.sort_index().values, dtype=torch.float)\n",
    "        \n",
    "        # Get positive data.(label = 1: link)\n",
    "        pos_data = self.data[self.data['label'] == 1]\n",
    "        # neg_data = self.data[self.data['label'] == 0]\n",
    "\n",
    "        # Get edge index.\n",
    "        graph = nx.from_pandas_edgelist(pos_data, 'from', 'to', edge_attr=None)\n",
    "\n",
    "        pair1 = [i[0] for i in graph.edges()]\n",
    "        pair2 = [i[1] for i in graph.edges()]\n",
    "        pos_edge_index = torch.LongTensor([pair1+pair2,pair2+pair1])\n",
    "\n",
    "        # Create Data object.\n",
    "        proc_graph = Data(x=x,\n",
    "                          edge_index=pos_edge_index,\n",
    "                          y=None)\n",
    "        print(proc_graph)\n",
    "\n",
    "        data, slices = self.collate([proc_graph])\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = Graph_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 8472])\n",
      "2708\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[   1,    4,    4,  ..., 1402, 2362, 1210],\n",
      "        [ 962, 2062, 1547,  ..., 2690, 2691, 2697]])\n",
      "None\n",
      "1433\n"
     ]
    }
   ],
   "source": [
    "for times, data in enumerate(demo, 1):\n",
    "    print(data)\n",
    "    print(data.x.size(0))\n",
    "    print(data.x)\n",
    "    print(data.edge_index)\n",
    "    print(data.y)\n",
    "    print(data.num_node_features)\n",
    "\n",
    "    # using this to check whether data.edge_index is fulfilled data.x values.\n",
    "    data.validate(raise_on_error=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, edge_index):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_channels, out_channels)\n",
    "        self.propagate = APPNP(K=1, alpha=0.15)\n",
    "\n",
    "    def forward(self, x, edge_index, not_prop=0):\n",
    "        x = self.linear1(x)\n",
    "        x = F.normalize(x, p=2, dim=-1) * 1.8\n",
    "        x = self.propagate(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_link_predictor(model, train_data, val_data, optimizer, n_epochs=200):\n",
    "    logger.info('Training Start')\n",
    "    for epoch in tqdm(range(1, n_epochs+1)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "        loss = model.recon_loss(z, train_data.edge_index)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_auc, val_ap = eval_link_predictor(model, train_data, val_data, None)\n",
    "        if epoch % 10 == 0:\n",
    "            # print('Epoch: {:03d}, TRAIN LOSS: {:.4f}, VAL AUC: {:.4f}, VAL AP: {:.4f}'.format(epoch, loss, val_auc, val_ap))\n",
    "            logger.info(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}, Val AP: {val_ap:.3f}')\n",
    "\n",
    "    logger.info('Training End --------------------------------')\n",
    "    return model\n",
    "\n",
    "def eval_link_predictor(model, train_data, val_data, test_data=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if test_data == None: \n",
    "            z = model.encode(train_data.x, train_data.edge_index)\n",
    "        else:\n",
    "            # 'test_data.edge_index' include 'train_data' & 'val_data' pos_edge_index.\n",
    "            z = model.encode(test_data.x, test_data.edge_index)\n",
    "\n",
    "    return model.test(z, val_data.pos_edge_label_index, val_data.neg_edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\mlg_ml\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "INFO Training Start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2708, 1433], edge_index=[2, 8472])\n",
      "Data(x=[2708, 1433], edge_index=[2, 7204], pos_edge_label=[3602], pos_edge_label_index=[2, 3602])\n",
      "Data(x=[2708, 1433], edge_index=[2, 7204], pos_edge_label=[211], pos_edge_label_index=[2, 211], neg_edge_label=[211], neg_edge_label_index=[2, 211])\n",
      "Data(x=[2708, 1433], edge_index=[2, 7626], pos_edge_label=[423], pos_edge_label_index=[2, 423], neg_edge_label=[423], neg_edge_label_index=[2, 423])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb2b3f5828c41f18c8bf7891fc8ce87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO Epoch: 010, Train Loss: 1.133, Val AUC: 0.751, Val AP: 0.776\n",
      "INFO Epoch: 020, Train Loss: 1.201, Val AUC: 0.679, Val AP: 0.682\n",
      "INFO Epoch: 030, Train Loss: 1.203, Val AUC: 0.671, Val AP: 0.679\n",
      "INFO Epoch: 040, Train Loss: 1.195, Val AUC: 0.655, Val AP: 0.664\n",
      "INFO Epoch: 050, Train Loss: 1.185, Val AUC: 0.680, Val AP: 0.677\n",
      "INFO Epoch: 060, Train Loss: 1.203, Val AUC: 0.659, Val AP: 0.656\n",
      "INFO Epoch: 070, Train Loss: 1.184, Val AUC: 0.677, Val AP: 0.675\n",
      "INFO Epoch: 080, Train Loss: 1.187, Val AUC: 0.665, Val AP: 0.663\n",
      "INFO Epoch: 090, Train Loss: 1.183, Val AUC: 0.672, Val AP: 0.673\n",
      "INFO Epoch: 100, Train Loss: 1.182, Val AUC: 0.658, Val AP: 0.658\n",
      "INFO Epoch: 110, Train Loss: 1.176, Val AUC: 0.674, Val AP: 0.673\n",
      "INFO Epoch: 120, Train Loss: 1.182, Val AUC: 0.668, Val AP: 0.668\n",
      "INFO Epoch: 130, Train Loss: 1.179, Val AUC: 0.670, Val AP: 0.669\n",
      "INFO Epoch: 140, Train Loss: 1.189, Val AUC: 0.662, Val AP: 0.662\n",
      "INFO Epoch: 150, Train Loss: 1.180, Val AUC: 0.679, Val AP: 0.678\n",
      "INFO Epoch: 160, Train Loss: 1.185, Val AUC: 0.668, Val AP: 0.672\n",
      "INFO Epoch: 170, Train Loss: 1.180, Val AUC: 0.661, Val AP: 0.666\n",
      "INFO Epoch: 180, Train Loss: 1.183, Val AUC: 0.673, Val AP: 0.677\n",
      "INFO Epoch: 190, Train Loss: 1.174, Val AUC: 0.674, Val AP: 0.678\n",
      "INFO Epoch: 200, Train Loss: 1.180, Val AUC: 0.669, Val AP: 0.671\n",
      "INFO Epoch: 210, Train Loss: 1.185, Val AUC: 0.665, Val AP: 0.665\n",
      "INFO Epoch: 220, Train Loss: 1.166, Val AUC: 0.680, Val AP: 0.686\n",
      "INFO Epoch: 230, Train Loss: 1.179, Val AUC: 0.675, Val AP: 0.677\n",
      "INFO Epoch: 240, Train Loss: 1.176, Val AUC: 0.677, Val AP: 0.676\n",
      "INFO Epoch: 250, Train Loss: 1.178, Val AUC: 0.678, Val AP: 0.682\n",
      "INFO Epoch: 260, Train Loss: 1.182, Val AUC: 0.671, Val AP: 0.669\n",
      "INFO Epoch: 270, Train Loss: 1.171, Val AUC: 0.687, Val AP: 0.691\n",
      "INFO Epoch: 280, Train Loss: 1.171, Val AUC: 0.701, Val AP: 0.711\n",
      "INFO Epoch: 290, Train Loss: 1.184, Val AUC: 0.670, Val AP: 0.670\n",
      "INFO Epoch: 300, Train Loss: 1.184, Val AUC: 0.651, Val AP: 0.649\n",
      "INFO Training End --------------------------------\n",
      "INFO Test AUC: 0.675, Test AP: 0.673\n"
     ]
    }
   ],
   "source": [
    "data = demo.data\n",
    "data = T.NormalizeFeatures()(data)\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(num_val=0.05, \n",
    "                                                    num_test=0.1, \n",
    "                                                    split_labels=True, \n",
    "                                                    is_undirected=True, \n",
    "                                                    add_negative_train_samples=False\n",
    "                                                    )(data)\n",
    "print(data)\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GAE(Encoder(data.num_features, 64, train_data.edge_index)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "model = train_link_predictor(model, train_data, val_data, optimizer, n_epochs=300)\n",
    "test_auc, test_ap = eval_link_predictor(model, train_data, test_data, test_data)\n",
    "# print(f\"Test AUC: {test_auc:.3f}, Test AP: {test_ap:.3f}\")\n",
    "logger.info(f\"Test AUC: {test_auc:.3f}, Test AP: {test_ap:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in tqdm(range(1, 200+1)):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     z = model.encode(data.x, data.edge_index)\n",
    "\n",
    "#     loss = model.recon_loss(z, train_data.pos_edge_label_index)\n",
    "#     loss = loss + (1/train_data.num_nodes) * model.kl_loss()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     val_auc, val_ap = eval_link_predictor(model, val_data)\n",
    "#     if epoch % 10 == 0:\n",
    "#         print('Epoch: {:03d}, TRAIN LOSS: {:.4f}, VAL AUC: {:.4f}, VAL AP: {:.4f}'.format(epoch, loss, val_auc, val_ap))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(data_path+'raw/test.csv')\n",
    "test_feats = pd.read_csv(data_path+'raw/content.csv', delimiter='\\t', header=None, index_col=0)\n",
    "test_x = torch.tensor(test_feats.sort_index().values, dtype=torch.float)\n",
    "test_id = test_df['id'].values\n",
    "test_edge_index = torch.tensor(test_df[['from', 'to']].values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4559, 0.9760, 0.9253, 0.7663, 0.7521, 0.8544, 0.8814, 0.2172, 0.8532,\n",
      "        0.4659, 0.4615, 0.9066, 0.6769, 0.8192, 0.5639, 0.6941, 0.5068, 0.8609,\n",
      "        0.4046, 0.7240, 0.9997, 0.6451, 0.8915, 0.3801, 0.4174, 0.4500, 0.9158,\n",
      "        0.4923, 0.7314, 0.7779, 0.4655, 0.9744, 0.9454, 0.9838, 0.9826, 0.6548,\n",
      "        0.6930, 0.8715, 0.9438, 0.4547, 0.8844, 0.6759, 0.5002, 0.3781, 0.4889,\n",
      "        0.3719, 0.7303, 0.5119, 0.9730, 0.4754, 0.5594, 0.5116, 0.4955, 0.5769,\n",
      "        0.8655, 0.5549, 0.9770, 0.4166, 0.3652, 0.9873, 0.8994, 0.4411, 0.5387,\n",
      "        0.4174, 0.5706, 0.8665, 0.6413, 0.9499, 0.2844, 0.5174, 0.5094, 0.8362,\n",
      "        0.8755, 0.4922, 0.9585, 0.3869, 0.9751, 0.9305, 0.6518, 0.7793, 0.5941,\n",
      "        0.3688, 0.6996, 0.9486, 0.9328, 0.5949, 0.9387, 0.4713, 0.5686, 0.9110,\n",
      "        0.7375, 0.7933, 0.7143, 0.4767, 0.4765, 0.3759, 0.9228, 0.4603, 0.5729,\n",
      "        0.5473, 0.7596, 0.8389, 0.5505, 0.8645, 0.6019, 0.5733, 0.6477, 0.9578,\n",
      "        0.9077, 0.9846, 0.4128, 0.4335, 0.6315, 0.9779, 0.9165, 0.5225, 0.9226,\n",
      "        0.4660, 0.8666, 0.4113, 0.5794, 0.6684, 0.4725, 0.8091, 0.4729, 0.4393,\n",
      "        0.7234, 0.9522, 0.4234, 0.6996, 0.9592, 0.3580, 0.5840, 0.6255, 0.8590,\n",
      "        0.9606, 0.5310, 0.4784, 0.4803, 0.7678, 0.4670, 0.3886, 0.7294, 0.2525,\n",
      "        0.6041, 0.4643, 0.7698, 0.7209, 0.8390, 0.2180, 0.9385, 0.9108, 0.6726,\n",
      "        0.4454, 0.5002, 0.5073, 0.7423, 0.9323, 0.5169, 0.8914, 0.8095, 0.9623,\n",
      "        0.4628, 0.4533, 0.6049, 0.7711, 0.4729, 0.3365, 0.5472, 0.3657, 0.9992,\n",
      "        0.5085, 0.9530, 0.6181, 0.4719, 0.7992, 0.3391, 0.8021, 0.6293, 0.9600,\n",
      "        0.5053, 0.5634, 0.8299, 0.4779, 0.6710, 0.7979, 0.9566, 0.9776, 0.9503,\n",
      "        0.5328, 0.5012, 0.9031, 0.4218, 0.4394, 0.5520, 0.4163, 0.7475, 0.4973,\n",
      "        0.9974, 0.4407, 0.8983, 0.9905, 0.4441, 0.4126, 0.9741, 0.9938, 0.4835,\n",
      "        0.9781, 0.5131, 0.7028, 0.9381, 0.4022, 0.9623, 0.4593, 0.5471, 0.7907,\n",
      "        0.6108, 0.9132, 0.4508, 0.3719, 0.3344, 0.4110, 0.4759, 0.6485, 0.6189,\n",
      "        0.5640, 0.6126, 0.9238, 0.9263, 0.4951, 0.9010, 0.4485, 0.9543, 0.3993,\n",
      "        0.9494, 0.7798, 0.4572, 0.5743, 0.9792, 0.7987, 0.8762, 0.7438, 0.5964,\n",
      "        0.5562, 0.5224, 0.6841, 0.8229, 0.8340, 0.9799, 0.4670, 0.6852, 0.6678,\n",
      "        0.5020, 0.9799, 0.4302, 0.8754, 0.5539, 0.8592, 0.6785, 0.5117, 0.9898,\n",
      "        0.6937, 0.4403, 0.6662, 0.9233, 0.4193, 0.4839, 0.5447, 0.8859, 0.4549,\n",
      "        0.9915, 0.5883, 0.3193, 0.5124, 0.4190, 0.8595, 0.4126, 0.4902, 0.8483,\n",
      "        0.4335, 0.4438, 0.4801, 0.6919, 0.9981, 0.9165, 0.4858, 0.7707, 0.4324,\n",
      "        0.5734, 0.8641, 0.8688, 0.8685, 0.5911, 0.3988, 0.5198, 0.4886, 0.5125,\n",
      "        0.5345, 0.9892, 0.9304, 0.5955, 0.9084, 0.4688, 0.5838, 0.5954, 0.4761,\n",
      "        0.9868, 0.7152, 0.4510, 0.4896, 0.5606, 0.9079, 0.6434, 0.4208, 0.5050,\n",
      "        0.9246, 0.7176, 0.4355, 0.8781, 0.6530, 0.9350, 0.5122, 0.8737, 0.3848,\n",
      "        0.5754, 0.5662, 0.7200, 0.9623, 0.8348, 0.5380, 0.9070, 0.7932, 0.5016,\n",
      "        0.6822, 0.6049, 0.5806, 0.3674, 0.4693, 0.8709, 0.3919, 0.5739, 0.6200,\n",
      "        0.4706, 0.5114, 0.7571, 0.8091, 0.6706, 0.9756, 0.9867, 0.9972, 0.4903,\n",
      "        0.4875, 0.9159, 0.8901, 0.4982, 0.9306, 0.5670, 0.4374, 0.9603, 0.5558,\n",
      "        0.6863, 0.4007, 0.6088, 0.4928, 0.5024, 0.6399, 0.9091, 0.3911, 0.5830,\n",
      "        0.9518, 0.4264, 0.8983, 0.4819, 0.9292, 0.8925, 0.8260, 0.9104, 0.6765,\n",
      "        0.5563, 0.3808, 0.5405, 0.5144, 0.8506, 0.3272, 0.7910, 0.3082, 0.4602,\n",
      "        0.4229, 0.5530, 0.4664, 0.4200, 0.8126, 0.4407, 0.4455, 0.4500, 0.4238,\n",
      "        0.6404, 0.5915, 0.5433, 0.9122, 0.4522, 0.4369, 0.9625, 0.5366, 0.4857,\n",
      "        0.8439, 0.2993, 0.9254, 0.6956, 0.6054, 0.7619, 0.9025, 0.9716, 0.9460,\n",
      "        0.4372, 0.9682, 0.8965, 0.9245, 0.8498, 0.6348, 0.4320, 0.9756, 0.9816,\n",
      "        0.8734, 0.9233, 0.5107, 0.4487, 0.5680, 0.5326, 0.8728, 0.8146, 0.6658,\n",
      "        0.3713, 0.5063, 0.8327, 0.5819, 0.4435, 0.6269, 0.5490, 0.9484, 0.4728,\n",
      "        0.9804, 0.4737, 0.4138, 0.5666, 0.8899, 0.4948, 0.7730, 0.4849, 0.9580,\n",
      "        0.5672, 0.9848, 0.9623, 0.9945, 0.9817, 0.9262, 0.9927, 0.6396, 0.4744,\n",
      "        0.9505, 0.8392, 0.8493, 0.4755, 0.5773, 0.4905, 0.9494, 0.5054, 0.8153,\n",
      "        0.9657, 0.9688, 0.6331, 0.9872, 0.5968, 0.7317, 0.8266, 0.1974, 0.9741,\n",
      "        0.9074, 0.8919, 0.6679, 0.8726, 0.8565, 0.9185, 0.7837, 0.9702, 0.7116,\n",
      "        0.7677, 0.9298, 0.7880, 0.9602, 0.5342, 0.5384, 0.9464, 0.9700, 0.5417,\n",
      "        0.9623, 0.6731, 0.2679, 0.4772, 0.8416, 0.4056, 0.9936, 0.3811, 0.5620,\n",
      "        0.5704, 0.9425, 0.7126, 0.7087, 0.4687, 0.9582, 0.7780, 0.4227, 0.4448,\n",
      "        0.4203, 0.3959, 0.3336, 0.6154, 0.7363, 0.3981, 0.5529, 0.7076, 0.9726,\n",
      "        0.5253, 0.7439, 0.6910, 0.5213, 0.5658, 0.5789, 0.9768, 0.5965, 0.5298,\n",
      "        0.7630, 0.4095, 0.5075, 0.5170, 0.9341, 0.4603, 0.8936, 0.8666, 0.3962,\n",
      "        0.9064, 0.9336, 0.9010, 0.6433, 0.9905, 0.9799, 0.4013, 0.8807, 0.4524,\n",
      "        0.3888, 0.9065, 0.4316, 0.6150, 0.9442, 0.5010, 0.9781, 0.6056, 0.6752,\n",
      "        0.9931, 0.6827, 0.3918, 0.5781, 0.7226, 0.4186, 0.4901, 0.9538, 0.5644,\n",
      "        0.4918, 0.5034, 0.5278, 0.8649, 0.8730, 0.5738, 0.9879, 0.4328, 0.6130,\n",
      "        0.4381, 0.4580, 0.4247, 0.7414, 0.4426, 0.3810, 0.9855, 0.9310, 0.5811,\n",
      "        0.7849, 0.8929, 0.5443, 0.4665, 0.4846, 0.7800, 0.4827, 0.4482, 0.9013,\n",
      "        0.9268, 0.9367, 0.5117, 0.4521, 0.5586, 0.7502, 0.9474, 0.8493, 0.5320,\n",
      "        0.4935, 0.3860, 0.8471, 0.5324, 0.4774, 0.4063, 0.5670, 0.3435, 0.8608,\n",
      "        0.5718, 0.8910, 0.3063, 0.9220, 0.5276, 0.1600, 0.6910, 0.3728, 0.4735,\n",
      "        0.8719, 0.4603, 0.6620, 0.9009, 0.5042, 0.4440, 0.8952, 0.9880, 0.5511,\n",
      "        0.7899, 0.9781, 0.4606, 0.7499, 0.3635, 0.5013, 0.7573, 0.4431, 0.9895,\n",
      "        0.4975, 0.9420, 0.4814, 0.4832, 0.9740])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(test_data.x, test_data.edge_index)\n",
    "    out = model.decode(z, test_edge_index).view(-1)\n",
    "    print(out)\n",
    "    # out = torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['id', 'prob']\n",
    "out = out.numpy()\n",
    "output_csv = []\n",
    "for ind, val in enumerate(test_id):\n",
    "    output_csv.append([val, str(out[ind])])\n",
    "output_csv = pd.DataFrame(output_csv, columns=header)\n",
    "output_csv.to_csv(data_path+'submission/'+store_file+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64049391f96ba131a9e04c522b3e94cd43efdce572641ac76d85c52ad35b8cda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
