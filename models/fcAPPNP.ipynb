{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from logs import log\n",
    "import torch\n",
    "# # from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import os\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, GCNConv, APPNP\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import from_networkx, negative_sampling, to_networkx\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fcAPPNP model version logs:\n",
    "    * ver1: fcAPPNP first try.\n",
    "          |_2: Use the testing node embedding for testing & uploading.\n",
    "    * ver2:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Datasets:\n",
    "    * id: edge id, \n",
    "    * from & to: 'from' node point to 'to' node, \n",
    "    * label: connect or not.\n",
    "    * content: containing each node's attribute.\n",
    "\n",
    "   Evaluate:\n",
    "    * AUC: area under ROC curve\n",
    "    * AP: average precision\n",
    "\"\"\"\n",
    "data_path = './dataset1/'\n",
    "model_version = 'fcAPPNP_ver2'\n",
    "upload_dataset_info = '_submission'\n",
    "store_file = model_version + upload_dataset_info\n",
    "tra_val_store_file = model_version + '_2' + upload_dataset_info\n",
    "log_file = 'logs/' + store_file + '.log'\n",
    "logger = log(path=data_path, file=log_file)\n",
    "\n",
    "df_train = pd.read_csv(data_path+'raw/train.csv').sort_values('from')\n",
    "df_test = pd.read_csv(data_path+'raw/test.csv')\n",
    "df_content = pd.read_csv(data_path+'raw/content.csv', delimiter='\\t', header=None)\n",
    "df_upload = pd.read_csv(data_path+'raw/upload.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature shape: (877, 1704)\n"
     ]
    }
   ],
   "source": [
    "print(f'Node feature shape: {df_content.shape}')\n",
    "tmp_node_feats = df_content.set_index(0)\n",
    "tmp_node_ids = tmp_node_feats.index.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>E2202</td>\n",
       "      <td>470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>E937</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>E2414</td>\n",
       "      <td>742</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>E3176</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>E960</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>E403</td>\n",
       "      <td>466</td>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>E343</td>\n",
       "      <td>640</td>\n",
       "      <td>874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>E2565</td>\n",
       "      <td>290</td>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>E2136</td>\n",
       "      <td>612</td>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>E1493</td>\n",
       "      <td>378</td>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2572 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   to  from  label\n",
       "266   E2202  470     0      0\n",
       "191    E937  689     0      0\n",
       "891   E2414  742     0      0\n",
       "1066  E3176  677     0      1\n",
       "268    E960  260     0      0\n",
       "...     ...  ...   ...    ...\n",
       "313    E403  466   873      0\n",
       "894    E343  640   874      1\n",
       "2105  E2565  290   875      1\n",
       "1511  E2136  612   875      1\n",
       "469   E1493  378   875      0\n",
       "\n",
       "[2572 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_dataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(Graph_dataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['train.csv', 'content.csv']\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['train.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        self.data = pd.read_csv(self.raw_paths[0]).sort_values('from')\n",
    "        node_feats = pd.read_csv(self.raw_paths[1], delimiter='\\t', header=None, index_col=0)\n",
    "        \n",
    "        # Get node features. [num_nodes, num_node_features]\n",
    "        x = torch.tensor(node_feats.sort_index().values, dtype=torch.float)\n",
    "        \n",
    "        # Get positive data.(label = 1: link)\n",
    "        pos_data = self.data[self.data['label'] == 1]\n",
    "        # neg_data = self.data[self.data['label'] == 0]\n",
    "\n",
    "        # Get edge index.\n",
    "        graph = nx.from_pandas_edgelist(pos_data, 'from', 'to', edge_attr=None)\n",
    "\n",
    "        pair1 = [i[0] for i in graph.edges()]\n",
    "        pair2 = [i[1] for i in graph.edges()]\n",
    "        pos_edge_index = torch.LongTensor([pair1+pair2,pair2+pair1])\n",
    "\n",
    "        # Create Data object.\n",
    "        proc_graph = Data(x=x,\n",
    "                          edge_index=pos_edge_index,\n",
    "                          y=None)\n",
    "        print(proc_graph)\n",
    "\n",
    "        data, slices = self.collate([proc_graph])\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Total content.csv nodes = 2708\n",
    "   Total train.csv nodes = 2704\n",
    "   Total train.csv positive link nodes = 2590\n",
    "\"\"\"\n",
    "demo = Graph_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[877, 1703], edge_index=[2, 2368])\n",
      "877\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]])\n",
      "1703\n"
     ]
    }
   ],
   "source": [
    "for times, data in enumerate(demo, 1):\n",
    "    print(data)\n",
    "    print(data.x.size(0))\n",
    "    print(data.x)\n",
    "    print(data.num_node_features)\n",
    "\n",
    "    # using this to check whether data.edge_index is fulfilled data.x values.\n",
    "    data.validate(raise_on_error=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fcAPPNP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels) -> None:\n",
    "        super(fcAPPNP, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_channels, out_channels)\n",
    "        self.propagate = APPNP(K=1, alpha=0.15)\n",
    "    \n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.linear1(x)\n",
    "        x = F.normalize(x, p=2, dim=-1) * 1.8\n",
    "        x = self.propagate(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "    \n",
    "    # def decode_all(self, z):\n",
    "    #     prob_adj = torch.matmul(z, z.t()) # z @ z.t()\n",
    "    #     return(prob_adj > 0).nonzero(as_tuple=False).t()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_link_predictor(model, train_data, val_data, optimizer, criterion, n_epochs=200):\n",
    "    logger.info('Training Start')\n",
    "    for epoch in tqdm(range(1, n_epochs+1)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "        # sampling training negatives for every training epoch\n",
    "        neg_edge_index = negative_sampling(edge_index=train_data.edge_index,\n",
    "                                           num_nodes=train_data.num_nodes,\n",
    "                                           num_neg_samples=train_data.edge_label_index.size(1),\n",
    "                                           method='sparse')\n",
    "        \n",
    "        edge_label_index = torch.cat([train_data.edge_label_index, \n",
    "                                      neg_edge_index], \n",
    "                                      dim=-1)\n",
    "\n",
    "\n",
    "        edge_label = torch.cat([train_data.edge_label,\n",
    "                                train_data.edge_label.new_zeros(neg_edge_index.size(1))], \n",
    "                                dim=0)\n",
    "        \n",
    "        out = model.decode(z, edge_label_index).view(-1)\n",
    "\n",
    "        loss = criterion(out, edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_auc, val_ap = eval_link_predictor(model, train_data, val_data, None)\n",
    "        # print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}')\n",
    "        if epoch % 10 == 0:\n",
    "            # print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}, Val AP: {val_ap:.3f}')\n",
    "            logger.info(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}, Val AP: {val_ap:.3f}')\n",
    "\n",
    "    logger.info('Training End --------------------------------')\n",
    "    return model\n",
    "\n",
    "def eval_link_predictor(model, train_data, val_data, test_data=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if test_data == None: \n",
    "            z = model.encode(train_data.x, train_data.edge_index)\n",
    "        else:\n",
    "            # 'test_data.edge_index' include 'train_data' & 'val_data' pos_edge_index.\n",
    "            z = model.encode(test_data.x, test_data.edge_index)\n",
    "\n",
    "        out = model.decode(z, val_data.edge_label_index).view(-1)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        auc = roc_auc_score(val_data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "        ap = average_precision_score(val_data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "    return auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\mlg_ml\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "INFO Training Start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[877, 1703], edge_index=[2, 2368])\n",
      "Data(x=[877, 1703], edge_index=[2, 2134], edge_label=[1067], edge_label_index=[2, 1067])\n",
      "Data(x=[877, 1703], edge_index=[2, 2134], edge_label=[124], edge_label_index=[2, 124])\n",
      "Data(x=[877, 1703], edge_index=[2, 2258], edge_label=[250], edge_label_index=[2, 250])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b27ca8dd6141baafa3e15fbe2ae985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO Epoch: 010, Train Loss: 0.532, Val AUC: 0.850, Val AP: 0.872\n",
      "INFO Epoch: 020, Train Loss: 0.465, Val AUC: 0.894, Val AP: 0.909\n",
      "INFO Epoch: 030, Train Loss: 0.445, Val AUC: 0.937, Val AP: 0.940\n",
      "INFO Epoch: 040, Train Loss: 0.436, Val AUC: 0.957, Val AP: 0.959\n",
      "INFO Epoch: 050, Train Loss: 0.430, Val AUC: 0.966, Val AP: 0.967\n",
      "INFO Epoch: 060, Train Loss: 0.422, Val AUC: 0.972, Val AP: 0.973\n",
      "INFO Epoch: 070, Train Loss: 0.405, Val AUC: 0.973, Val AP: 0.975\n",
      "INFO Epoch: 080, Train Loss: 0.415, Val AUC: 0.974, Val AP: 0.975\n",
      "INFO Epoch: 090, Train Loss: 0.417, Val AUC: 0.975, Val AP: 0.977\n",
      "INFO Epoch: 100, Train Loss: 0.411, Val AUC: 0.972, Val AP: 0.976\n",
      "INFO Epoch: 110, Train Loss: 0.412, Val AUC: 0.972, Val AP: 0.976\n",
      "INFO Epoch: 120, Train Loss: 0.402, Val AUC: 0.973, Val AP: 0.977\n",
      "INFO Epoch: 130, Train Loss: 0.404, Val AUC: 0.974, Val AP: 0.979\n",
      "INFO Epoch: 140, Train Loss: 0.386, Val AUC: 0.973, Val AP: 0.978\n",
      "INFO Epoch: 150, Train Loss: 0.398, Val AUC: 0.973, Val AP: 0.978\n",
      "INFO Epoch: 160, Train Loss: 0.396, Val AUC: 0.973, Val AP: 0.977\n",
      "INFO Epoch: 170, Train Loss: 0.402, Val AUC: 0.973, Val AP: 0.977\n",
      "INFO Epoch: 180, Train Loss: 0.396, Val AUC: 0.969, Val AP: 0.975\n",
      "INFO Epoch: 190, Train Loss: 0.398, Val AUC: 0.966, Val AP: 0.973\n",
      "INFO Epoch: 200, Train Loss: 0.390, Val AUC: 0.969, Val AP: 0.974\n",
      "INFO Epoch: 210, Train Loss: 0.401, Val AUC: 0.963, Val AP: 0.971\n",
      "INFO Epoch: 220, Train Loss: 0.394, Val AUC: 0.967, Val AP: 0.974\n",
      "INFO Epoch: 230, Train Loss: 0.392, Val AUC: 0.962, Val AP: 0.970\n",
      "INFO Epoch: 240, Train Loss: 0.398, Val AUC: 0.969, Val AP: 0.974\n",
      "INFO Epoch: 250, Train Loss: 0.393, Val AUC: 0.970, Val AP: 0.974\n",
      "INFO Epoch: 260, Train Loss: 0.387, Val AUC: 0.973, Val AP: 0.974\n",
      "INFO Epoch: 270, Train Loss: 0.393, Val AUC: 0.979, Val AP: 0.980\n",
      "INFO Epoch: 280, Train Loss: 0.383, Val AUC: 0.977, Val AP: 0.978\n",
      "INFO Epoch: 290, Train Loss: 0.389, Val AUC: 0.975, Val AP: 0.977\n",
      "INFO Epoch: 300, Train Loss: 0.392, Val AUC: 0.975, Val AP: 0.977\n",
      "INFO Training End --------------------------------\n",
      "INFO Test AUC: 0.940, Test AP: 0.954\n",
      "INFO tra_val Test AUC: 0.939, Test AP: 0.952\n"
     ]
    }
   ],
   "source": [
    "data = demo.data\n",
    "data = T.NormalizeFeatures()(data)\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(num_val=0.05, \n",
    "                                                    num_test=0.1, \n",
    "                                                    is_undirected=True, \n",
    "                                                    add_negative_train_samples=False\n",
    "                                                    )(data)\n",
    "print(data)\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = fcAPPNP(data.num_features, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.005)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = train_link_predictor(model, train_data, val_data, optimizer, criterion, n_epochs=300)\n",
    "\n",
    "test_auc, test_ap = eval_link_predictor(model, train_data, test_data, None)\n",
    "logger.info(f\"Test AUC: {test_auc:.3f}, Test AP: {test_ap:.3f}\")\n",
    "test_auc, test_ap = eval_link_predictor(model, train_data, test_data, test_data)\n",
    "logger.info(f\"tra_val Test AUC: {test_auc:.3f}, Test AP: {test_ap:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(data_path+'raw/test.csv')\n",
    "test_feats = pd.read_csv(data_path+'raw/content.csv', delimiter='\\t', header=None, index_col=0)\n",
    "test_x = torch.tensor(test_feats.sort_index().values, dtype=torch.float)\n",
    "test_id = test_df['id'].values\n",
    "test_edge_index = torch.tensor(test_df[['from', 'to']].values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4198, 0.9822, 0.9093, 0.7215, 0.7458, 0.8618, 0.9084, 0.4951, 0.8971,\n",
      "        0.5359, 0.4727, 0.9087, 0.7160, 0.8273, 0.5823, 0.8636, 0.5078, 0.8522,\n",
      "        0.4287, 0.5022, 0.9995, 0.9559, 0.8286, 0.3855, 0.4303, 0.3476, 0.9180,\n",
      "        0.4993, 0.7421, 0.7212, 0.3894, 0.9724, 0.9224, 0.9753, 0.9987, 0.5872,\n",
      "        0.7308, 0.9225, 0.8904, 0.4273, 0.8803, 0.5545, 0.4280, 0.3805, 0.5630,\n",
      "        0.4926, 0.7022, 0.4164, 0.9833, 0.6401, 0.6991, 0.4797, 0.5197, 0.4002,\n",
      "        0.8539, 0.4055, 0.9484, 0.4432, 0.6218, 0.9849, 0.8545, 0.5412, 0.4046,\n",
      "        0.3531, 0.5292, 0.8854, 0.5217, 0.4199, 0.4051, 0.4818, 0.5045, 0.7044,\n",
      "        0.8740, 0.4987, 0.9508, 0.4643, 0.9937, 0.9025, 0.5694, 0.9503, 0.6443,\n",
      "        0.3258, 0.6458, 0.7960, 0.9416, 0.7169, 0.9326, 0.5287, 0.7267, 0.9240,\n",
      "        0.8876, 0.8691, 0.6737, 0.5114, 0.5809, 0.3931, 0.9870, 0.4895, 0.4739,\n",
      "        0.5042, 0.9155, 0.8724, 0.6815, 0.6339, 0.6443, 0.7530, 0.6472, 0.9660,\n",
      "        0.9132, 0.9859, 0.3619, 0.4297, 0.7251, 0.9746, 0.9314, 0.3042, 0.9475,\n",
      "        0.4540, 0.9235, 0.3637, 0.4119, 0.6580, 0.5217, 0.6657, 0.5137, 0.4923,\n",
      "        0.7001, 0.9874, 0.4582, 0.6453, 0.9464, 0.4060, 0.7588, 0.6181, 0.9021,\n",
      "        0.7717, 0.4326, 0.4289, 0.4207, 0.5037, 0.4872, 0.6278, 0.7817, 0.9450,\n",
      "        0.4728, 0.3926, 0.5138, 0.6589, 0.9511, 0.2171, 0.9069, 0.9617, 0.6400,\n",
      "        0.4527, 0.5340, 0.6245, 0.7836, 0.8640, 0.4522, 0.8024, 0.8119, 0.9623,\n",
      "        0.4498, 0.4477, 0.7384, 0.6793, 0.5023, 0.3553, 0.5090, 0.3371, 0.9996,\n",
      "        0.5497, 0.8070, 0.4367, 0.4574, 0.5523, 0.4876, 0.7919, 0.5444, 0.9205,\n",
      "        0.4687, 0.9965, 0.8457, 0.4509, 0.5565, 0.8443, 0.9462, 0.9845, 0.9450,\n",
      "        0.6113, 0.4785, 0.9623, 0.3860, 0.5408, 0.5087, 0.4718, 0.7662, 0.5310,\n",
      "        0.9967, 0.5808, 0.9248, 0.8850, 0.4774, 0.4133, 0.9704, 0.9867, 0.3304,\n",
      "        0.9662, 0.5705, 0.7656, 0.8373, 0.5002, 0.9623, 0.3973, 0.5821, 0.8951,\n",
      "        0.5233, 0.9322, 0.6056, 0.4776, 0.4924, 0.3489, 0.4927, 0.7455, 0.6580,\n",
      "        0.3101, 0.5109, 0.9141, 0.9218, 0.5118, 0.9239, 0.3904, 0.9540, 0.4014,\n",
      "        0.9591, 0.7858, 0.3733, 0.4378, 0.9726, 0.6449, 0.8568, 0.8830, 0.5110,\n",
      "        0.4596, 0.4049, 0.7194, 0.8455, 0.9659, 0.9785, 0.4254, 0.7023, 0.6692,\n",
      "        0.5678, 0.9880, 0.5408, 0.7616, 0.6138, 0.8605, 0.5889, 0.4318, 0.9916,\n",
      "        0.6913, 0.4971, 0.4578, 0.9310, 0.4335, 0.4769, 0.5356, 0.8410, 0.5443,\n",
      "        0.8706, 0.5531, 0.5219, 0.4958, 0.3868, 0.8556, 0.4957, 0.4296, 0.8114,\n",
      "        0.5781, 0.3364, 0.3982, 0.9798, 0.9984, 0.9378, 0.4442, 0.7802, 0.5618,\n",
      "        0.4542, 0.9265, 0.8749, 0.9512, 0.7926, 0.4593, 0.5465, 0.5151, 0.4451,\n",
      "        0.4747, 0.9732, 0.9250, 0.7943, 0.9291, 0.5039, 0.6631, 0.6275, 0.5528,\n",
      "        0.9927, 0.5280, 0.4479, 0.4990, 0.6191, 0.9426, 0.5505, 0.4513, 0.4298,\n",
      "        0.9886, 0.9201, 0.5108, 0.9388, 0.4838, 0.9393, 0.5878, 0.8808, 0.4380,\n",
      "        0.6933, 0.4541, 0.4642, 0.7790, 0.9345, 0.3361, 0.8889, 0.8874, 0.4033,\n",
      "        0.7111, 0.5930, 0.5749, 0.4037, 0.8238, 0.8798, 0.4287, 0.6089, 0.7345,\n",
      "        0.4986, 0.4623, 0.7506, 0.8248, 0.5515, 0.8939, 0.9473, 0.9967, 0.4165,\n",
      "        0.4063, 0.9554, 0.8462, 0.7150, 0.8559, 0.6618, 0.5395, 0.9566, 0.7231,\n",
      "        0.6540, 0.5127, 0.8216, 0.4319, 0.5106, 0.6102, 0.8098, 0.4468, 0.6423,\n",
      "        0.9376, 0.5100, 0.9101, 0.4814, 0.8080, 0.8758, 0.9193, 0.9082, 0.8262,\n",
      "        0.4974, 0.4305, 0.5604, 0.5136, 0.6819, 0.3885, 0.8304, 0.4142, 0.4077,\n",
      "        0.4191, 0.6119, 0.4382, 0.2983, 0.8229, 0.5002, 0.5332, 0.4699, 0.4373,\n",
      "        0.4338, 0.5148, 0.5623, 0.8468, 0.3721, 0.4399, 0.9234, 0.6670, 0.4315,\n",
      "        0.9769, 0.8379, 0.9247, 0.7952, 0.6204, 0.6746, 0.9182, 0.9676, 0.9165,\n",
      "        0.4524, 0.9604, 0.9324, 0.9298, 0.8725, 0.5979, 0.4721, 0.9006, 0.9737,\n",
      "        0.9395, 0.9477, 0.5106, 0.4647, 0.5796, 0.5596, 0.8864, 0.7885, 0.6617,\n",
      "        0.4022, 0.3979, 0.8336, 0.8039, 0.4923, 0.7667, 0.6202, 0.9051, 0.4639,\n",
      "        0.9931, 0.4789, 0.5509, 0.4685, 0.8964, 0.4782, 0.6819, 0.4611, 0.9108,\n",
      "        0.6946, 0.9745, 0.9623, 0.9921, 0.9963, 0.8886, 0.9891, 0.6163, 0.4498,\n",
      "        0.6389, 0.7811, 0.8922, 0.5284, 0.4976, 0.4796, 0.9500, 0.6122, 0.8592,\n",
      "        0.9597, 0.9631, 0.6902, 0.9541, 0.5033, 0.7020, 0.7578, 0.9613, 0.8432,\n",
      "        0.8701, 0.8104, 0.6301, 0.8880, 0.9419, 0.9404, 0.9623, 0.6516, 0.6553,\n",
      "        0.5964, 0.9219, 0.8932, 0.9471, 0.5435, 0.5696, 0.9134, 0.9880, 0.5742,\n",
      "        0.8945, 0.7526, 0.4962, 0.4555, 0.9012, 0.3939, 0.9946, 0.3615, 0.3960,\n",
      "        0.5030, 0.9332, 0.3234, 0.7081, 0.4319, 0.9610, 0.8297, 0.5551, 0.4281,\n",
      "        0.6599, 0.4731, 0.3778, 0.5179, 0.7227, 0.4178, 0.7717, 0.5896, 0.9861,\n",
      "        0.4899, 0.8739, 0.8869, 0.3011, 0.4617, 0.5846, 0.9210, 0.3214, 0.4518,\n",
      "        0.4603, 0.3676, 0.4296, 0.5224, 0.9652, 0.5048, 0.8534, 0.9235, 0.4064,\n",
      "        0.9242, 0.9660, 0.9110, 0.6224, 0.9468, 0.9860, 0.4751, 0.8265, 0.5096,\n",
      "        0.3280, 0.8909, 0.8529, 0.8332, 0.9976, 0.4492, 0.7107, 0.6223, 0.6600,\n",
      "        0.9989, 0.7293, 0.5178, 0.6893, 0.4736, 0.3806, 0.4881, 0.9382, 0.5560,\n",
      "        0.4572, 0.4972, 0.4790, 0.8624, 0.8134, 0.5064, 0.9924, 0.4652, 0.5478,\n",
      "        0.6030, 0.5239, 0.4627, 0.7592, 0.4628, 0.7064, 0.9932, 0.8408, 0.4616,\n",
      "        0.7809, 0.6934, 0.5237, 0.8087, 0.5054, 0.8083, 0.4512, 0.4277, 0.9265,\n",
      "        0.6614, 0.9486, 0.5278, 0.5666, 0.5254, 0.7201, 0.8999, 0.7315, 0.5576,\n",
      "        0.4366, 0.4319, 0.8772, 0.8387, 0.4418, 0.3550, 0.5627, 0.3499, 0.8544,\n",
      "        0.5490, 0.8943, 0.5156, 0.9439, 0.5569, 0.3461, 0.8869, 0.3560, 0.4390,\n",
      "        0.7878, 0.5534, 0.4202, 0.8508, 0.4824, 0.5049, 0.8745, 0.9952, 0.7921,\n",
      "        0.7801, 0.9433, 0.4434, 0.9222, 0.5153, 0.4468, 0.7160, 0.4929, 0.9912,\n",
      "        0.3956, 0.9296, 0.6968, 0.4937, 0.9282])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    out = model.decode(z, test_edge_index).view(-1)\n",
    "    out = torch.sigmoid(out)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['id', 'prob']\n",
    "out = out.numpy()\n",
    "output_csv = []\n",
    "for ind, val in enumerate(test_id):\n",
    "    output_csv.append([val, str(out[ind])])\n",
    "output_csv = pd.DataFrame(output_csv, columns=header)\n",
    "output_csv.to_csv(data_path+'submission/'+store_file+'.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tra_val inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(data_path+'raw/test.csv')\n",
    "test_feats = pd.read_csv(data_path+'raw/content.csv', delimiter='\\t', header=None, index_col=0)\n",
    "test_x = torch.tensor(test_feats.sort_index().values, dtype=torch.float)\n",
    "test_id = test_df['id'].values\n",
    "test_edge_index = torch.tensor(test_df[['from', 'to']].values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4202, 0.9811, 0.9156, 0.7378, 0.7458, 0.8615, 0.9012, 0.4974, 0.8808,\n",
      "        0.5361, 0.4725, 0.8912, 0.7153, 0.8273, 0.5822, 0.8551, 0.5078, 0.8497,\n",
      "        0.4288, 0.4922, 0.9997, 0.9534, 0.8527, 0.3855, 0.4317, 0.3524, 0.9180,\n",
      "        0.4995, 0.7425, 0.7081, 0.3950, 0.9716, 0.9244, 0.9719, 0.9988, 0.5855,\n",
      "        0.7255, 0.9220, 0.8850, 0.4308, 0.8803, 0.5543, 0.4335, 0.3825, 0.5550,\n",
      "        0.4926, 0.7006, 0.4185, 0.9853, 0.6353, 0.6991, 0.4790, 0.5197, 0.4002,\n",
      "        0.8536, 0.4055, 0.9506, 0.4454, 0.6232, 0.9850, 0.8532, 0.5405, 0.4050,\n",
      "        0.3562, 0.5288, 0.8854, 0.5216, 0.4272, 0.3854, 0.4818, 0.5046, 0.7240,\n",
      "        0.8740, 0.4986, 0.9508, 0.4452, 0.9937, 0.9173, 0.5641, 0.9502, 0.6798,\n",
      "        0.3262, 0.6453, 0.8269, 0.9361, 0.7091, 0.9261, 0.5275, 0.7197, 0.9240,\n",
      "        0.8795, 0.8549, 0.6548, 0.5110, 0.5751, 0.3932, 0.9879, 0.4895, 0.4739,\n",
      "        0.5013, 0.9185, 0.8724, 0.6752, 0.6368, 0.6443, 0.7521, 0.6537, 0.9657,\n",
      "        0.9131, 0.9860, 0.3619, 0.4297, 0.7241, 0.9746, 0.9254, 0.3042, 0.9475,\n",
      "        0.4552, 0.9134, 0.3548, 0.4122, 0.6751, 0.5215, 0.6839, 0.5140, 0.4925,\n",
      "        0.7001, 0.9850, 0.4386, 0.6453, 0.9464, 0.4064, 0.7610, 0.6173, 0.9189,\n",
      "        0.8283, 0.4864, 0.4670, 0.4211, 0.5567, 0.4872, 0.6278, 0.7555, 0.9445,\n",
      "        0.4725, 0.4052, 0.5324, 0.6575, 0.9561, 0.2267, 0.9016, 0.9628, 0.6396,\n",
      "        0.4528, 0.5340, 0.6251, 0.7836, 0.9006, 0.4524, 0.7967, 0.8066, 0.9623,\n",
      "        0.4499, 0.4477, 0.7378, 0.6792, 0.4899, 0.3648, 0.5091, 0.3454, 0.9997,\n",
      "        0.5496, 0.8575, 0.4367, 0.4577, 0.5628, 0.4538, 0.7784, 0.5403, 0.9247,\n",
      "        0.4687, 0.9968, 0.8457, 0.4509, 0.5392, 0.8144, 0.9518, 0.9831, 0.9450,\n",
      "        0.6355, 0.4787, 0.9623, 0.3872, 0.5408, 0.5086, 0.4738, 0.7662, 0.4781,\n",
      "        0.9953, 0.5809, 0.9210, 0.8861, 0.4780, 0.4329, 0.9704, 0.9843, 0.3483,\n",
      "        0.9620, 0.5800, 0.7645, 0.8317, 0.5001, 0.9623, 0.3977, 0.5806, 0.8940,\n",
      "        0.5233, 0.9288, 0.6056, 0.4786, 0.4924, 0.3489, 0.4927, 0.6731, 0.6574,\n",
      "        0.3101, 0.5111, 0.9194, 0.9218, 0.5119, 0.9193, 0.4044, 0.9533, 0.4014,\n",
      "        0.9591, 0.7636, 0.3753, 0.4379, 0.9725, 0.6449, 0.8278, 0.8947, 0.5110,\n",
      "        0.4595, 0.4049, 0.7146, 0.8455, 0.9677, 0.9765, 0.4254, 0.6998, 0.6683,\n",
      "        0.5681, 0.9867, 0.5400, 0.7718, 0.6086, 0.8603, 0.5881, 0.4320, 0.9928,\n",
      "        0.6912, 0.4972, 0.4578, 0.9310, 0.4338, 0.4769, 0.5575, 0.8158, 0.5438,\n",
      "        0.8984, 0.5531, 0.5165, 0.4959, 0.3870, 0.8556, 0.4957, 0.4298, 0.8095,\n",
      "        0.5781, 0.3365, 0.3993, 0.9775, 0.9984, 0.9336, 0.4255, 0.7802, 0.5619,\n",
      "        0.4542, 0.9192, 0.8587, 0.9416, 0.8020, 0.4593, 0.5465, 0.5153, 0.4454,\n",
      "        0.4747, 0.9895, 0.9250, 0.7915, 0.9291, 0.5038, 0.6605, 0.6266, 0.5525,\n",
      "        0.9914, 0.5280, 0.4477, 0.5009, 0.6191, 0.9435, 0.6218, 0.4548, 0.4299,\n",
      "        0.9884, 0.9198, 0.5114, 0.9379, 0.5338, 0.9392, 0.5866, 0.8518, 0.4394,\n",
      "        0.6930, 0.4541, 0.4638, 0.7784, 0.9323, 0.3373, 0.8983, 0.8870, 0.4033,\n",
      "        0.7110, 0.5922, 0.5748, 0.4137, 0.8159, 0.8679, 0.4299, 0.6087, 0.7608,\n",
      "        0.4984, 0.4939, 0.7506, 0.8248, 0.5547, 0.9040, 0.9445, 0.9964, 0.4165,\n",
      "        0.4064, 0.9554, 0.8420, 0.6819, 0.8468, 0.6584, 0.5395, 0.9566, 0.7231,\n",
      "        0.6526, 0.5128, 0.8215, 0.4563, 0.4937, 0.6020, 0.8032, 0.4468, 0.6416,\n",
      "        0.9353, 0.5074, 0.9101, 0.4820, 0.8046, 0.8758, 0.9193, 0.9080, 0.8397,\n",
      "        0.4974, 0.4305, 0.5604, 0.5139, 0.6703, 0.3909, 0.8304, 0.4163, 0.4144,\n",
      "        0.4193, 0.6119, 0.4398, 0.2983, 0.8201, 0.5002, 0.5329, 0.4620, 0.4430,\n",
      "        0.4338, 0.5149, 0.5803, 0.8769, 0.3720, 0.4399, 0.9209, 0.6669, 0.4320,\n",
      "        0.9799, 0.8522, 0.8893, 0.7748, 0.6363, 0.6746, 0.9182, 0.9668, 0.9165,\n",
      "        0.4532, 0.9555, 0.9301, 0.9298, 0.8582, 0.5979, 0.4763, 0.9023, 0.9705,\n",
      "        0.9395, 0.9477, 0.5107, 0.4665, 0.5796, 0.5598, 0.8699, 0.8027, 0.6583,\n",
      "        0.4052, 0.3979, 0.8333, 0.8049, 0.4928, 0.6967, 0.6164, 0.9446, 0.4682,\n",
      "        0.9921, 0.4789, 0.5509, 0.4479, 0.8732, 0.4736, 0.6978, 0.4613, 0.9102,\n",
      "        0.6879, 0.9744, 0.9623, 0.9906, 0.9959, 0.8886, 0.9881, 0.6140, 0.4509,\n",
      "        0.6495, 0.7798, 0.8873, 0.5283, 0.4977, 0.4797, 0.9500, 0.6119, 0.8592,\n",
      "        0.9596, 0.9649, 0.6827, 0.9544, 0.4899, 0.7015, 0.7521, 0.9642, 0.8403,\n",
      "        0.8687, 0.8041, 0.6302, 0.8880, 0.9475, 0.9313, 0.9623, 0.6360, 0.6552,\n",
      "        0.5958, 0.9219, 0.9040, 0.9434, 0.5436, 0.5696, 0.9106, 0.9874, 0.5717,\n",
      "        0.8945, 0.7518, 0.5359, 0.4555, 0.9191, 0.3939, 0.9946, 0.3618, 0.4006,\n",
      "        0.5035, 0.9332, 0.3385, 0.7074, 0.4400, 0.9610, 0.8289, 0.5540, 0.4473,\n",
      "        0.6701, 0.4396, 0.3778, 0.5179, 0.7222, 0.4181, 0.7481, 0.5882, 0.9836,\n",
      "        0.4900, 0.8739, 0.8586, 0.3011, 0.4617, 0.5839, 0.9157, 0.3049, 0.4536,\n",
      "        0.6268, 0.3686, 0.4336, 0.5224, 0.9544, 0.5053, 0.8519, 0.9134, 0.4078,\n",
      "        0.9242, 0.9660, 0.9191, 0.6223, 0.9526, 0.9879, 0.4724, 0.8767, 0.5076,\n",
      "        0.3359, 0.8909, 0.8528, 0.8332, 0.9972, 0.4514, 0.7161, 0.6274, 0.6593,\n",
      "        0.9989, 0.7183, 0.5178, 0.6888, 0.4680, 0.3808, 0.4887, 0.9361, 0.5386,\n",
      "        0.4585, 0.4969, 0.4790, 0.8501, 0.8009, 0.5092, 0.9928, 0.4652, 0.5478,\n",
      "        0.6030, 0.5242, 0.4686, 0.7513, 0.4666, 0.7025, 0.9925, 0.8405, 0.4618,\n",
      "        0.7992, 0.6993, 0.5230, 0.7946, 0.5055, 0.8075, 0.4515, 0.4342, 0.9218,\n",
      "        0.6413, 0.9486, 0.5203, 0.5666, 0.5090, 0.7184, 0.9108, 0.7310, 0.5575,\n",
      "        0.4373, 0.4124, 0.8702, 0.8377, 0.4420, 0.3553, 0.5627, 0.3518, 0.8544,\n",
      "        0.5490, 0.8943, 0.5157, 0.9353, 0.5569, 0.3231, 0.8586, 0.3561, 0.4393,\n",
      "        0.7732, 0.5521, 0.4397, 0.8507, 0.4798, 0.5049, 0.8658, 0.9951, 0.7921,\n",
      "        0.7801, 0.9471, 0.4434, 0.9250, 0.5066, 0.4493, 0.7155, 0.4929, 0.9912,\n",
      "        0.3958, 0.9057, 0.6968, 0.4938, 0.9387])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(test_data.x, test_data.edge_index)\n",
    "\n",
    "    out = model.decode(z, test_edge_index).view(-1)\n",
    "    out = torch.sigmoid(out)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['id', 'prob']\n",
    "out = out.numpy()\n",
    "output_csv = []\n",
    "for ind, val in enumerate(test_id):\n",
    "    output_csv.append([val, str(out[ind])])\n",
    "output_csv = pd.DataFrame(output_csv, columns=header)\n",
    "output_csv.to_csv(data_path+'submission/'+tra_val_store_file+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64049391f96ba131a9e04c522b3e94cd43efdce572641ac76d85c52ad35b8cda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
