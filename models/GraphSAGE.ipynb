{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from logs import log\n",
    "import torch\n",
    "# # from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import os\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, GCNConv\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import from_networkx, negative_sampling, to_networkx\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphSAGE model version logs:\n",
    "    * ver1: GraphSAGE first try.\n",
    "          |_2: Use the testing node embedding for testing & uploading.\n",
    "    * ver2:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Datasets:\n",
    "    * id: edge id, \n",
    "    * from & to: 'from' node point to 'to' node, \n",
    "    * label: connect or not.\n",
    "    * content: containing each node's attribute.\n",
    "\n",
    "   Evaluate:\n",
    "    * AUC: area under ROC curve\n",
    "    * AP: average precision\n",
    "\"\"\"\n",
    "data_path = './dataset1/'\n",
    "model_version = 'GraphSAGE_ver2'\n",
    "upload_dataset_info = '_submission'\n",
    "store_file = model_version + upload_dataset_info\n",
    "tra_val_store_file = model_version + '_2' + upload_dataset_info\n",
    "log_file = 'logs/' + store_file + '.log'\n",
    "logger = log(path=data_path, file=log_file)\n",
    "\n",
    "df_train = pd.read_csv(data_path+'raw/train.csv').sort_values('from')\n",
    "df_test = pd.read_csv(data_path+'raw/test.csv')\n",
    "df_content = pd.read_csv(data_path+'raw/content.csv', delimiter='\\t', header=None)\n",
    "df_upload = pd.read_csv(data_path+'raw/upload.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature shape: (877, 1704)\n"
     ]
    }
   ],
   "source": [
    "print(f'Node feature shape: {df_content.shape}')\n",
    "tmp_node_feats = df_content.set_index(0)\n",
    "tmp_node_ids = tmp_node_feats.index.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>to</th>\n",
       "      <th>from</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>E2202</td>\n",
       "      <td>470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>E937</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>E2414</td>\n",
       "      <td>742</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>E3176</td>\n",
       "      <td>677</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>E960</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>E403</td>\n",
       "      <td>466</td>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>E343</td>\n",
       "      <td>640</td>\n",
       "      <td>874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>E2565</td>\n",
       "      <td>290</td>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>E2136</td>\n",
       "      <td>612</td>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>E1493</td>\n",
       "      <td>378</td>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2572 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   to  from  label\n",
       "266   E2202  470     0      0\n",
       "191    E937  689     0      0\n",
       "891   E2414  742     0      0\n",
       "1066  E3176  677     0      1\n",
       "268    E960  260     0      0\n",
       "...     ...  ...   ...    ...\n",
       "313    E403  466   873      0\n",
       "894    E343  640   874      1\n",
       "2105  E2565  290   875      1\n",
       "1511  E2136  612   875      1\n",
       "469   E1493  378   875      0\n",
       "\n",
       "[2572 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_dataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(Graph_dataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['train.csv', 'content.csv']\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['train.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        self.data = pd.read_csv(self.raw_paths[0]).sort_values('from')\n",
    "        node_feats = pd.read_csv(self.raw_paths[1], delimiter='\\t', header=None, index_col=0)\n",
    "        \n",
    "        # Get node features. [num_nodes, num_node_features]\n",
    "        x = torch.tensor(node_feats.sort_index().values, dtype=torch.float)\n",
    "        \n",
    "        # Get positive data.(label = 1: link)\n",
    "        pos_data = self.data[self.data['label'] == 1]\n",
    "        # neg_data = self.data[self.data['label'] == 0]\n",
    "\n",
    "        # Get edge index.\n",
    "        graph = nx.from_pandas_edgelist(pos_data, 'from', 'to', edge_attr=None)\n",
    "\n",
    "        pair1 = [i[0] for i in graph.edges()]\n",
    "        pair2 = [i[1] for i in graph.edges()]\n",
    "        pos_edge_index = torch.LongTensor([pair1+pair2,pair2+pair1])\n",
    "\n",
    "        # Create Data object.\n",
    "        proc_graph = Data(x=x,\n",
    "                          edge_index=pos_edge_index,\n",
    "                          y=None)\n",
    "        print(proc_graph)\n",
    "\n",
    "        data, slices = self.collate([proc_graph])\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Total content.csv nodes = 2708\n",
    "   Total train.csv nodes = 2704\n",
    "   Total train.csv positive link nodes = 2590\n",
    "\"\"\"\n",
    "demo = Graph_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[877, 1703], edge_index=[2, 2368])\n",
      "877\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]])\n",
      "1703\n"
     ]
    }
   ],
   "source": [
    "for times, data in enumerate(demo, 1):\n",
    "    print(data)\n",
    "    print(data.x.size(0))\n",
    "    print(data.x)\n",
    "    print(data.num_node_features)\n",
    "\n",
    "    # using this to check whether data.edge_index is fulfilled data.x values.\n",
    "    data.validate(raise_on_error=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels) -> None:\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        # self.fc1 = nn.Linear(in_channels, hidden_channels)\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        # self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "    \n",
    "    def encode(self, x, edge_index):\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "    \n",
    "    # def decode_all(self, z):\n",
    "    #     prob_adj = torch.matmul(z, z.t()) # z @ z.t()\n",
    "    #     return(prob_adj > 0).nonzero(as_tuple=False).t()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_link_predictor(model, train_data, val_data, optimizer, criterion, n_epochs=200):\n",
    "    logger.info('Training Start')\n",
    "    for epoch in tqdm(range(1, n_epochs+1)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "        # sampling training negatives for every training epoch\n",
    "        neg_edge_index = negative_sampling(edge_index=train_data.edge_index,\n",
    "                                           num_nodes=train_data.num_nodes,\n",
    "                                           num_neg_samples=train_data.edge_label_index.size(1),\n",
    "                                           method='sparse')\n",
    "        \n",
    "        edge_label_index = torch.cat([train_data.edge_label_index, \n",
    "                                      neg_edge_index], \n",
    "                                      dim=-1)\n",
    "\n",
    "\n",
    "        edge_label = torch.cat([train_data.edge_label,\n",
    "                                train_data.edge_label.new_zeros(neg_edge_index.size(1))], \n",
    "                                dim=0)\n",
    "        \n",
    "        out = model.decode(z, edge_label_index).view(-1)\n",
    "\n",
    "        loss = criterion(out, edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        val_auc, val_ap = eval_link_predictor(model, train_data, val_data, None)\n",
    "        # print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}')\n",
    "        if epoch % 10 == 0:\n",
    "            # print(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}, Val AP: {val_ap:.3f}')\n",
    "            logger.info(f'Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}, Val AP: {val_ap:.3f}')\n",
    "\n",
    "    logger.info('Training End --------------------------------')\n",
    "    return model\n",
    "\n",
    "def eval_link_predictor(model, train_data, val_data, test_data=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if test_data == None: \n",
    "            z = model.encode(train_data.x, train_data.edge_index)\n",
    "        else:\n",
    "            # 'test_data.edge_index' include 'train_data' & 'val_data' pos_edge_index.\n",
    "            z = model.encode(test_data.x, test_data.edge_index)\n",
    "\n",
    "        out = model.decode(z, val_data.edge_label_index).view(-1)\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        auc = roc_auc_score(val_data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "        ap = average_precision_score(val_data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "    return auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\mlg_ml\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n",
      "INFO Training Start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[877, 1703], edge_index=[2, 2368])\n",
      "Data(x=[877, 1703], edge_index=[2, 2134], edge_label=[1067], edge_label_index=[2, 1067])\n",
      "Data(x=[877, 1703], edge_index=[2, 2134], edge_label=[124], edge_label_index=[2, 124])\n",
      "Data(x=[877, 1703], edge_index=[2, 2258], edge_label=[250], edge_label_index=[2, 250])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b36382c76141b38efb195af36e497c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO Epoch: 010, Train Loss: 0.492, Val AUC: 0.857, Val AP: 0.862\n",
      "INFO Epoch: 020, Train Loss: 0.440, Val AUC: 0.835, Val AP: 0.851\n",
      "INFO Epoch: 030, Train Loss: 0.422, Val AUC: 0.824, Val AP: 0.850\n",
      "INFO Epoch: 040, Train Loss: 0.410, Val AUC: 0.821, Val AP: 0.844\n",
      "INFO Epoch: 050, Train Loss: 0.403, Val AUC: 0.824, Val AP: 0.846\n",
      "INFO Epoch: 060, Train Loss: 0.384, Val AUC: 0.816, Val AP: 0.843\n",
      "INFO Epoch: 070, Train Loss: 0.391, Val AUC: 0.815, Val AP: 0.838\n",
      "INFO Epoch: 080, Train Loss: 0.395, Val AUC: 0.809, Val AP: 0.831\n",
      "INFO Epoch: 090, Train Loss: 0.400, Val AUC: 0.806, Val AP: 0.842\n",
      "INFO Epoch: 100, Train Loss: 0.387, Val AUC: 0.811, Val AP: 0.843\n",
      "INFO Epoch: 110, Train Loss: 0.398, Val AUC: 0.803, Val AP: 0.842\n",
      "INFO Epoch: 120, Train Loss: 0.381, Val AUC: 0.820, Val AP: 0.853\n",
      "INFO Epoch: 130, Train Loss: 0.392, Val AUC: 0.819, Val AP: 0.851\n",
      "INFO Epoch: 140, Train Loss: 0.387, Val AUC: 0.809, Val AP: 0.844\n",
      "INFO Epoch: 150, Train Loss: 0.385, Val AUC: 0.780, Val AP: 0.828\n",
      "INFO Epoch: 160, Train Loss: 0.387, Val AUC: 0.760, Val AP: 0.811\n",
      "INFO Epoch: 170, Train Loss: 0.389, Val AUC: 0.751, Val AP: 0.807\n",
      "INFO Epoch: 180, Train Loss: 0.381, Val AUC: 0.796, Val AP: 0.842\n",
      "INFO Epoch: 190, Train Loss: 0.380, Val AUC: 0.794, Val AP: 0.841\n",
      "INFO Epoch: 200, Train Loss: 0.383, Val AUC: 0.797, Val AP: 0.841\n",
      "INFO Epoch: 210, Train Loss: 0.377, Val AUC: 0.806, Val AP: 0.844\n",
      "INFO Epoch: 220, Train Loss: 0.375, Val AUC: 0.809, Val AP: 0.848\n",
      "INFO Epoch: 230, Train Loss: 0.379, Val AUC: 0.792, Val AP: 0.837\n",
      "INFO Epoch: 240, Train Loss: 0.372, Val AUC: 0.772, Val AP: 0.823\n",
      "INFO Epoch: 250, Train Loss: 0.377, Val AUC: 0.785, Val AP: 0.832\n",
      "INFO Epoch: 260, Train Loss: 0.390, Val AUC: 0.791, Val AP: 0.834\n",
      "INFO Epoch: 270, Train Loss: 0.381, Val AUC: 0.805, Val AP: 0.836\n",
      "INFO Epoch: 280, Train Loss: 0.383, Val AUC: 0.778, Val AP: 0.825\n",
      "INFO Epoch: 290, Train Loss: 0.384, Val AUC: 0.789, Val AP: 0.833\n",
      "INFO Epoch: 300, Train Loss: 0.377, Val AUC: 0.801, Val AP: 0.839\n",
      "INFO Training End --------------------------------\n",
      "INFO Test AUC: 0.777, Test AP: 0.828\n",
      "INFO tra_val Test AUC: 0.791, Test AP: 0.840\n"
     ]
    }
   ],
   "source": [
    "data = demo.data\n",
    "# data = T.NormalizeFeatures()(data)\n",
    "train_data, val_data, test_data = T.RandomLinkSplit(num_val=0.05, \n",
    "                                                    num_test=0.1, \n",
    "                                                    is_undirected=True, \n",
    "                                                    add_negative_train_samples=False\n",
    "                                                    )(data)\n",
    "print(data)\n",
    "print(train_data)\n",
    "print(val_data)\n",
    "print(test_data)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphSAGE(data.num_features, 128, 32).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = train_link_predictor(model, train_data, val_data, optimizer, criterion, n_epochs=300)\n",
    "\n",
    "test_auc, test_ap = eval_link_predictor(model, train_data, test_data, None)\n",
    "logger.info(f\"Test AUC: {test_auc:.3f}, Test AP: {test_ap:.3f}\")\n",
    "test_auc, test_ap = eval_link_predictor(model, train_data, test_data, test_data)\n",
    "logger.info(f\"tra_val Test AUC: {test_auc:.3f}, Test AP: {test_ap:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(data_path+'raw/test.csv')\n",
    "test_feats = pd.read_csv(data_path+'raw/content.csv', delimiter='\\t', header=None, index_col=0)\n",
    "test_x = torch.tensor(test_feats.sort_index().values, dtype=torch.float)\n",
    "test_id = test_df['id'].values\n",
    "test_edge_index = torch.tensor(test_df[['from', 'to']].values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5979, 0.5345, 0.9908, 0.7228, 0.6173, 0.9602, 0.3545, 0.3924, 0.6223,\n",
      "        0.4935, 0.5534, 0.6499, 0.4678, 0.4396, 0.4999, 0.9680, 0.4979, 0.9331,\n",
      "        0.4666, 0.7545, 1.0000, 0.8338, 0.9932, 0.2889, 0.4950, 0.4839, 0.9437,\n",
      "        0.5264, 0.5731, 0.8637, 0.2001, 0.9537, 0.9908, 0.5634, 0.5160, 0.6532,\n",
      "        0.4309, 0.9773, 0.8396, 0.5055, 0.5364, 0.3715, 0.3952, 0.3796, 0.7347,\n",
      "        0.4578, 0.5158, 0.4834, 0.5701, 0.4808, 0.3883, 0.4608, 0.4819, 0.4704,\n",
      "        0.9481, 0.4858, 0.9966, 0.4967, 0.5404, 0.0565, 0.9881, 0.4741, 0.4474,\n",
      "        0.4135, 0.5277, 0.6216, 0.6123, 0.9350, 0.4892, 0.4812, 0.4474, 0.6050,\n",
      "        0.6940, 0.3169, 0.9752, 0.5625, 0.8489, 0.9954, 0.6031, 0.9354, 0.8832,\n",
      "        0.3064, 0.6382, 0.4176, 0.9883, 0.4770, 0.9940, 0.3751, 0.3646, 0.9245,\n",
      "        0.8280, 0.8297, 0.7189, 0.4827, 0.5056, 0.4827, 0.9947, 0.5624, 0.5211,\n",
      "        0.5477, 0.6429, 0.9744, 0.7631, 0.4999, 0.6316, 0.7329, 0.7871, 0.6502,\n",
      "        0.9408, 0.9368, 0.3488, 0.5343, 0.6028, 0.9878, 0.9388, 0.7089, 0.9818,\n",
      "        0.7296, 0.9879, 0.6622, 0.4853, 0.6822, 0.5752, 0.2234, 0.4663, 0.5545,\n",
      "        0.4454, 0.9804, 0.4935, 0.7183, 0.9729, 0.5033, 0.4084, 0.5038, 0.9964,\n",
      "        0.8052, 0.4141, 0.6577, 0.3645, 0.3277, 0.5393, 0.4379, 0.9516, 0.3743,\n",
      "        0.4981, 0.3477, 0.1042, 0.8413, 0.0671, 0.2015, 0.3569, 0.9726, 0.4205,\n",
      "        0.5062, 0.4658, 0.5821, 0.8070, 0.6060, 0.5452, 0.7255, 0.8251, 0.5256,\n",
      "        0.5839, 0.5160, 0.7521, 0.8585, 0.5178, 0.5823, 0.6859, 0.4053, 0.9409,\n",
      "        0.3802, 0.3922, 0.5122, 0.5084, 0.5114, 0.4294, 0.6538, 0.8314, 0.5211,\n",
      "        0.4563, 0.5991, 0.8278, 0.3118, 0.5075, 0.6834, 0.9951, 0.9947, 0.9750,\n",
      "        0.6436, 0.5203, 0.9750, 0.3518, 0.4417, 0.3240, 0.5804, 0.5118, 0.5787,\n",
      "        0.8932, 0.4560, 0.9893, 0.4739, 0.5290, 0.4113, 0.9931, 0.9805, 0.3570,\n",
      "        0.9652, 0.4017, 0.3418, 0.9856, 0.5078, 0.5513, 0.4391, 0.3102, 0.9022,\n",
      "        0.7831, 0.9437, 0.4005, 0.4051, 0.8990, 0.8491, 0.4274, 0.5907, 0.4876,\n",
      "        0.4193, 0.5318, 0.9858, 0.9821, 0.4040, 0.5092, 0.5673, 0.9959, 0.5713,\n",
      "        0.9804, 0.9738, 0.2147, 0.4979, 0.9740, 0.5122, 0.9551, 0.4984, 0.5027,\n",
      "        0.5064, 0.2430, 0.6691, 0.7353, 0.4586, 0.9082, 0.5029, 0.6562, 0.3404,\n",
      "        0.4458, 0.8180, 0.3130, 0.9772, 0.5631, 0.9391, 0.6729, 0.3327, 0.9851,\n",
      "        0.7095, 0.4553, 0.5133, 0.9693, 0.5134, 0.4826, 0.3993, 0.9847, 0.5908,\n",
      "        0.5487, 0.3931, 0.3676, 0.4825, 0.4569, 0.5183, 0.6611, 0.5549, 0.7653,\n",
      "        0.5808, 0.4896, 0.3958, 0.0377, 0.9999, 0.9895, 0.2770, 0.4655, 0.4576,\n",
      "        0.2763, 0.9584, 0.9787, 0.5649, 0.1625, 0.3912, 0.4722, 0.4804, 0.4764,\n",
      "        0.7822, 0.9999, 0.9556, 0.5379, 0.9930, 0.6446, 0.5224, 0.5780, 0.4544,\n",
      "        0.9087, 0.5310, 0.7149, 0.4159, 0.5127, 0.1824, 0.8401, 0.4214, 0.4767,\n",
      "        0.4263, 0.9644, 0.4488, 0.9666, 0.5281, 0.9879, 0.5173, 0.8338, 0.5215,\n",
      "        0.5146, 0.4746, 0.5021, 0.7137, 0.9793, 0.2435, 0.9893, 0.9807, 0.4576,\n",
      "        0.7887, 0.5371, 0.4733, 0.2784, 0.5204, 0.9671, 0.2065, 0.4413, 0.4606,\n",
      "        0.4142, 0.4919, 0.9660, 0.9633, 0.6857, 0.4201, 0.8710, 0.9911, 0.4700,\n",
      "        0.4598, 0.9650, 0.7605, 0.5592, 0.7983, 0.4752, 0.5132, 0.9921, 0.5334,\n",
      "        0.4999, 0.6781, 0.6235, 0.5233, 0.4203, 0.5448, 0.9854, 0.5030, 0.7472,\n",
      "        0.9980, 0.5107, 0.4849, 0.3877, 0.9484, 0.9710, 0.5160, 0.9780, 0.3070,\n",
      "        0.5127, 0.3197, 0.6860, 0.4802, 0.2694, 0.5024, 0.8558, 0.4285, 0.5622,\n",
      "        0.4279, 0.5026, 0.5174, 0.5310, 0.7427, 0.3719, 0.3965, 0.3572, 0.4425,\n",
      "        0.6054, 0.6122, 0.5850, 0.9911, 0.5009, 0.7053, 0.9823, 0.4165, 0.5107,\n",
      "        0.4841, 0.1364, 0.9940, 0.9701, 0.5160, 0.6268, 0.6037, 0.9888, 0.9691,\n",
      "        0.5875, 0.9870, 0.9917, 0.9928, 0.7978, 0.3360, 0.6195, 0.2751, 0.9844,\n",
      "        0.9898, 0.9805, 0.3946, 0.4376, 0.4859, 0.4719, 0.9886, 0.8611, 0.6641,\n",
      "        0.3937, 0.3787, 0.8899, 0.5734, 0.5422, 0.4607, 0.6684, 0.9536, 0.5353,\n",
      "        0.4765, 0.4646, 0.6381, 0.6167, 0.9924, 0.5203, 0.0192, 0.4751, 0.3425,\n",
      "        0.5925, 0.3933, 0.9597, 0.7904, 0.9999, 0.5278, 0.9997, 0.3628, 0.5260,\n",
      "        0.7494, 0.8511, 0.8799, 0.7291, 0.5760, 0.5045, 0.9788, 0.4803, 0.5256,\n",
      "        0.9886, 0.9908, 0.3838, 0.2775, 0.8309, 0.7740, 0.9296, 0.3971, 0.8364,\n",
      "        0.5981, 0.9535, 0.9381, 0.9865, 0.9821, 0.9855, 0.6963, 0.2749, 0.5795,\n",
      "        0.6891, 0.9060, 0.6581, 0.9961, 0.5114, 0.5450, 0.9934, 0.2405, 0.5570,\n",
      "        0.5365, 0.7737, 0.3476, 0.4038, 0.9555, 0.5316, 0.4748, 0.3834, 0.5261,\n",
      "        0.3918, 0.9740, 0.5188, 0.5961, 0.5902, 0.7593, 0.9422, 0.4604, 0.5976,\n",
      "        0.3446, 0.5286, 0.4977, 0.5165, 0.6743, 0.5425, 0.7300, 0.4428, 0.9979,\n",
      "        0.5310, 0.5663, 0.5772, 0.3811, 0.6387, 0.5115, 0.6103, 0.2922, 0.4336,\n",
      "        0.5016, 0.7759, 0.6278, 0.2639, 0.9918, 0.5044, 0.9775, 0.9879, 0.7342,\n",
      "        0.9805, 0.9856, 0.7886, 0.5309, 0.6715, 0.9971, 0.5290, 0.6060, 0.5880,\n",
      "        0.3992, 0.9488, 0.8525, 0.8370, 0.7058, 0.6675, 0.9899, 0.3821, 0.6512,\n",
      "        0.9992, 0.5017, 0.6291, 0.4582, 0.0877, 0.4383, 0.5309, 0.9959, 0.4441,\n",
      "        0.4774, 0.5482, 0.4876, 0.9705, 0.6855, 0.6010, 0.9723, 0.4981, 0.5460,\n",
      "        0.5001, 0.5163, 0.3666, 0.7182, 0.8743, 0.7233, 0.6325, 0.9252, 0.5920,\n",
      "        0.6827, 0.5099, 0.4968, 0.4962, 0.5229, 0.9277, 0.4674, 0.5012, 0.4334,\n",
      "        0.5595, 0.9539, 0.3764, 0.5159, 0.2304, 0.7741, 0.9857, 0.5459, 0.5124,\n",
      "        0.6505, 0.4712, 0.5868, 0.9561, 0.4313, 0.3698, 0.8893, 0.2828, 0.5901,\n",
      "        0.3278, 0.5290, 0.5007, 0.9865, 0.4929, 0.2019, 0.5772, 0.5942, 0.5419,\n",
      "        0.9759, 0.5155, 0.6954, 0.4739, 0.6084, 0.4960, 0.3280, 0.5433, 0.5392,\n",
      "        0.9211, 0.9197, 0.5652, 0.4018, 0.3124, 0.4346, 0.6464, 0.4985, 0.9866,\n",
      "        0.3804, 0.9562, 0.5342, 0.4976, 0.9427])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    out = model.decode(z, test_edge_index).view(-1)\n",
    "    out = torch.sigmoid(out)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['id', 'prob']\n",
    "out = out.numpy()\n",
    "output_csv = []\n",
    "for ind, val in enumerate(test_id):\n",
    "    output_csv.append([val, str(out[ind])])\n",
    "output_csv = pd.DataFrame(output_csv, columns=header)\n",
    "output_csv.to_csv(data_path+'submission/'+store_file+'.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tra_val inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(data_path+'raw/test.csv')\n",
    "test_feats = pd.read_csv(data_path+'raw/content.csv', delimiter='\\t', header=None, index_col=0)\n",
    "test_x = torch.tensor(test_feats.sort_index().values, dtype=torch.float)\n",
    "test_id = test_df['id'].values\n",
    "test_edge_index = torch.tensor(test_df[['from', 'to']].values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5975, 0.5052, 0.9839, 0.6761, 0.6173, 0.9601, 0.3580, 0.3941, 0.6235,\n",
      "        0.4937, 0.5541, 0.6522, 0.4823, 0.4398, 0.5000, 0.9680, 0.4968, 0.9257,\n",
      "        0.4652, 0.7542, 1.0000, 0.8318, 0.9931, 0.2889, 0.4958, 0.4851, 0.9299,\n",
      "        0.5344, 0.5728, 0.8609, 0.2181, 0.9536, 0.9846, 0.5634, 0.5161, 0.6526,\n",
      "        0.4093, 0.9471, 0.8417, 0.5063, 0.8684, 0.3663, 0.3953, 0.3796, 0.7286,\n",
      "        0.4578, 0.7610, 0.4958, 0.8948, 0.4786, 0.4826, 0.4614, 0.4819, 0.4704,\n",
      "        0.9470, 0.4858, 0.9965, 0.4965, 0.5416, 0.0590, 0.9881, 0.4738, 0.4474,\n",
      "        0.4599, 0.5277, 0.6216, 0.6120, 0.9351, 0.5837, 0.4506, 0.4565, 0.6029,\n",
      "        0.6940, 0.3169, 0.9752, 0.5636, 0.8468, 0.9952, 0.6413, 0.9339, 0.8322,\n",
      "        0.2608, 0.5586, 0.4189, 0.9890, 0.4770, 0.9937, 0.3789, 0.3520, 0.9245,\n",
      "        0.8195, 0.8295, 0.7174, 0.4836, 0.5056, 0.4828, 0.9946, 0.5611, 0.5051,\n",
      "        0.5477, 0.6453, 0.9744, 0.7512, 0.5034, 0.6315, 0.7321, 0.7832, 0.6502,\n",
      "        0.9408, 0.9315, 0.3488, 0.5360, 0.6028, 0.9878, 0.9388, 0.7089, 0.9818,\n",
      "        0.6051, 0.9580, 0.6621, 0.4854, 0.6815, 0.5772, 0.2284, 0.4692, 0.5563,\n",
      "        0.4455, 0.9799, 0.4935, 0.7183, 0.9721, 0.5021, 0.4083, 0.4592, 0.9964,\n",
      "        0.7850, 0.4139, 0.6578, 0.3633, 0.3280, 0.5405, 0.4379, 0.9516, 0.3748,\n",
      "        0.4994, 0.3469, 0.1076, 0.8389, 0.0687, 0.1891, 0.3555, 0.9722, 0.4274,\n",
      "        0.5073, 0.4663, 0.5860, 0.8070, 0.8800, 0.5444, 0.7203, 0.8599, 0.5256,\n",
      "        0.5856, 0.4952, 0.7517, 0.8527, 0.4872, 0.5793, 0.6856, 0.4130, 0.9446,\n",
      "        0.3808, 0.3818, 0.5122, 0.4867, 0.5114, 0.4297, 0.6538, 0.8310, 0.5206,\n",
      "        0.4600, 0.5982, 0.8278, 0.3118, 0.5066, 0.6816, 0.9952, 0.9946, 0.9750,\n",
      "        0.6904, 0.5203, 0.9750, 0.3523, 0.4535, 0.3240, 0.5810, 0.5118, 0.5794,\n",
      "        0.9259, 0.4682, 0.9884, 0.4745, 0.4324, 0.4113, 0.9913, 0.9893, 0.3584,\n",
      "        0.9686, 0.4017, 0.3435, 0.9833, 0.5075, 0.5513, 0.4759, 0.3269, 0.9022,\n",
      "        0.7831, 0.8547, 0.4005, 0.4137, 0.8990, 0.8491, 0.4272, 0.5928, 0.4873,\n",
      "        0.4189, 0.5332, 0.9768, 0.9821, 0.4043, 0.5137, 0.5629, 0.9959, 0.5713,\n",
      "        0.9804, 0.9738, 0.2143, 0.4979, 0.9607, 0.5122, 0.9541, 0.4999, 0.4736,\n",
      "        0.5062, 0.2549, 0.5574, 0.7353, 0.4595, 0.9024, 0.5026, 0.6540, 0.3403,\n",
      "        0.4458, 0.8165, 0.3452, 0.9732, 0.5656, 0.9390, 0.6737, 0.3321, 0.9847,\n",
      "        0.7093, 0.4577, 0.5133, 0.9693, 0.5131, 0.4827, 0.4038, 0.9847, 0.5125,\n",
      "        0.9993, 0.3931, 0.3712, 0.4829, 0.4570, 0.5183, 0.6610, 0.5544, 0.7650,\n",
      "        0.5808, 0.4901, 0.3966, 0.0392, 0.9998, 0.9704, 0.2348, 0.5009, 0.4589,\n",
      "        0.2973, 0.9562, 0.9847, 0.5757, 0.1733, 0.3912, 0.4722, 0.4805, 0.4757,\n",
      "        0.7821, 0.9990, 0.8641, 0.5379, 0.9930, 0.6309, 0.5015, 0.5778, 0.4611,\n",
      "        0.9046, 0.5293, 0.7080, 0.4210, 0.5127, 0.1825, 0.8401, 0.4368, 0.4769,\n",
      "        0.4267, 0.9571, 0.4495, 0.9662, 0.8483, 0.9879, 0.5089, 0.7719, 0.4617,\n",
      "        0.5145, 0.4746, 0.5020, 0.7144, 0.9208, 0.2450, 0.9901, 0.8365, 0.4581,\n",
      "        0.7788, 0.5426, 0.4734, 0.2899, 0.5197, 0.9671, 0.2119, 0.4419, 0.4602,\n",
      "        0.4152, 0.4919, 0.9660, 0.9633, 0.6848, 0.4167, 0.9089, 0.9906, 0.4717,\n",
      "        0.4597, 0.9556, 0.7678, 0.6651, 0.7953, 0.4040, 0.5132, 0.9941, 0.5334,\n",
      "        0.5653, 0.6781, 0.6229, 0.5514, 0.4214, 0.5462, 0.9852, 0.5030, 0.7464,\n",
      "        0.9981, 0.5109, 0.4851, 0.3887, 0.9484, 0.9710, 0.5160, 0.9780, 0.3086,\n",
      "        0.5127, 0.3197, 0.6860, 0.4833, 0.2704, 0.5014, 0.8558, 0.4259, 0.5679,\n",
      "        0.4257, 0.5047, 0.5174, 0.5310, 0.7427, 0.3719, 0.3975, 0.3852, 0.4356,\n",
      "        0.6041, 0.6127, 0.5431, 0.9905, 0.5008, 0.6999, 0.9826, 0.4172, 0.5094,\n",
      "        0.4848, 0.1375, 0.9940, 0.9697, 0.5158, 0.6229, 0.6037, 0.9879, 0.9691,\n",
      "        0.5868, 0.9866, 0.9917, 0.9928, 0.8010, 0.3612, 0.6185, 0.4092, 0.9836,\n",
      "        0.9898, 0.9805, 0.3947, 0.4389, 0.4842, 0.4721, 0.9905, 0.8527, 0.6644,\n",
      "        0.3869, 0.3787, 0.8899, 0.5728, 0.5406, 0.4608, 0.6672, 0.9541, 0.5308,\n",
      "        0.4731, 0.4680, 0.6610, 0.6160, 0.9924, 0.5213, 0.0197, 0.4751, 0.3434,\n",
      "        0.5108, 0.3938, 0.9597, 0.7877, 0.9999, 0.5278, 0.9997, 0.3632, 0.5260,\n",
      "        0.7360, 0.8515, 0.9151, 0.7295, 0.5760, 0.5046, 0.9788, 0.4781, 0.5256,\n",
      "        0.9886, 0.9896, 0.3909, 0.2841, 0.8272, 0.7659, 0.9291, 0.3982, 0.8294,\n",
      "        0.5995, 0.9530, 0.9380, 0.9858, 0.9821, 0.9851, 0.6917, 0.2794, 0.5784,\n",
      "        0.6891, 0.9060, 0.6564, 0.9962, 0.4893, 0.5450, 0.9935, 0.2413, 0.5582,\n",
      "        0.5365, 0.7724, 0.3485, 0.4105, 0.9398, 0.5316, 0.4751, 0.3825, 0.4856,\n",
      "        0.4518, 0.9740, 0.5139, 0.5966, 0.5900, 0.7427, 0.9428, 0.4604, 0.5975,\n",
      "        0.3485, 0.5130, 0.4977, 0.5152, 0.6744, 0.5197, 0.7081, 0.4383, 0.9976,\n",
      "        0.5310, 0.5663, 0.5770, 0.3811, 0.6387, 0.5115, 0.7009, 0.2967, 0.3261,\n",
      "        0.5015, 0.7760, 0.6263, 0.2639, 0.9901, 0.5052, 0.9476, 0.9580, 0.7344,\n",
      "        0.9805, 0.9648, 0.7996, 0.5309, 0.6655, 0.9968, 0.5262, 0.8868, 0.5838,\n",
      "        0.4067, 0.9488, 0.8529, 0.8671, 0.7032, 0.6675, 0.9899, 0.3807, 0.6500,\n",
      "        0.9992, 0.5025, 0.6291, 0.4582, 0.0913, 0.4368, 0.5304, 0.9960, 0.4441,\n",
      "        0.4808, 0.5414, 0.4864, 0.9706, 0.6839, 0.6579, 0.9683, 0.4977, 0.5468,\n",
      "        0.5001, 0.4767, 0.3632, 0.7147, 0.8726, 0.7237, 0.6307, 0.8865, 0.5919,\n",
      "        0.6827, 0.5105, 0.4878, 0.4964, 0.5245, 0.9277, 0.4678, 0.5012, 0.4334,\n",
      "        0.5730, 0.9539, 0.4035, 0.5158, 0.2295, 0.7726, 0.9857, 0.5366, 0.5127,\n",
      "        0.6360, 0.4724, 0.5959, 0.9566, 0.4040, 0.3689, 0.8893, 0.2986, 0.5901,\n",
      "        0.3278, 0.5290, 0.5006, 0.9861, 0.4929, 0.2045, 0.5770, 0.5951, 0.5421,\n",
      "        0.9759, 0.5155, 0.6956, 0.4740, 0.5839, 0.4960, 0.3318, 0.5439, 0.5392,\n",
      "        0.9116, 0.9183, 0.5652, 0.4028, 0.2982, 0.4346, 0.6452, 0.4985, 0.9807,\n",
      "        0.3802, 0.9559, 0.5328, 0.4977, 0.9304])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z = model.encode(test_data.x, test_data.edge_index)\n",
    "\n",
    "    out = model.decode(z, test_edge_index).view(-1)\n",
    "    out = torch.sigmoid(out)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['id', 'prob']\n",
    "out = out.numpy()\n",
    "output_csv = []\n",
    "for ind, val in enumerate(test_id):\n",
    "    output_csv.append([val, str(out[ind])])\n",
    "output_csv = pd.DataFrame(output_csv, columns=header)\n",
    "output_csv.to_csv(data_path+'submission/'+tra_val_store_file+'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64049391f96ba131a9e04c522b3e94cd43efdce572641ac76d85c52ad35b8cda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
